{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raghad-Odwan/DermAI_Final_Training/blob/main/DermAI_FinalTraining_Model%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZGCMotfNWBs"
      },
      "source": [
        "# **DermAI: Final Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kOeQwg2nzzc"
      },
      "source": [
        "              Palestine Technical University - Kadoorie\n",
        "                \n",
        "              Department of Computer Systems Engineering\n",
        "\n",
        "              DermAI: Intelligent Skin Cancer Detection Using Convolutional     Neural Network & Transfer Learning Architectures\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdXUgsAURas7"
      },
      "source": [
        "### **About this notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evZzfPW4SA4F"
      },
      "source": [
        "This notebook performs the final training stage of the DermAI skin lesion classification model.\n",
        "\n",
        "After completing the cross-validation phase and identifying the best-performing fold, this notebook trains a final production model using the entire dataset (19,505 images). The goal is to leverage all available data to produce the most accurate and stable version of the model for deployment.\n",
        "\n",
        "#### **Main Functions of This Notebook**\n",
        "\n",
        "1. Load the best fold model trained during cross-validation.\n",
        "\n",
        "2. Automatically detect whether the model uses softmax (2-class) or sigmoid (binary) architecture.\n",
        "\n",
        "3. Freeze all layers and fine-tune the last 40 layers for targeted improvement.\n",
        "\n",
        "4. Prepare the full dataset with advanced augmentation and a small validation split for monitoring.\n",
        "\n",
        "5. Configure training using AdamW/Adam with optimized learning rate and regularization.\n",
        "\n",
        "6. Track performance using validation accuracy, early stopping, and learning rate scheduling.\n",
        "\n",
        "7. Save all outputs, including:\n",
        "\n",
        "* Best model (final_model_best.keras)\n",
        "\n",
        "* Full final model (final_model_complete.keras)\n",
        "\n",
        "* Training logs and summary\n",
        "\n",
        "* Accuracy/Loss curves\n",
        "\n",
        "##### **Purpose of This Notebook**\n",
        "\n",
        "This final training stage produces the single final model that will be used for:\n",
        "\n",
        "* Deployment\n",
        "\n",
        "* Grad-CAM visualization\n",
        "\n",
        "* Integration into the DermAI system\n",
        "\n",
        "It applies the hyperparameters validated during the cross-validation phase and ensures the model benefits from training on the full dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mALlPGHPsulm"
      },
      "source": [
        "###  \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GivXM-RTbqD",
        "outputId": "b67b85ab-2d68-4255-c605-0e10db3ac6a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD_tbCcoTdya",
        "outputId": "77406913-bd40-4cb6-bd94-39684ed79ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7yJb-UioTBgr",
        "outputId": "f087d856-6a0d-47a4-d302-3c91a5e25853"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "function ClickConnect(){\n",
              "    console.log(\"Preventing Colab timeout\");\n",
              "    document.querySelector(\"colab-toolbar-button#connect\").click();\n",
              "}\n",
              "setInterval(ClickConnect, 60000)\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%javascript\n",
        "function ClickConnect(){\n",
        "    console.log(\"Preventing Colab timeout\");\n",
        "    document.querySelector(\"colab-toolbar-button#connect\").click();\n",
        "}\n",
        "setInterval(ClickConnect, 60000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZelZKCwTaSY"
      },
      "source": [
        "___________________________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRI3v9sS9Qa5"
      },
      "source": [
        "## **Part One: Dataset Load & prepare**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MtslpsqEsU88"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KO0Dubm6tC_4"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "\n",
        "# Paths define\n",
        "BASE_DIR = \"/content/drive/MyDrive/Dataset/Dataset\"\n",
        "METADATA_PATH = \"/content/drive/MyDrive/ai/data/df_metadata.csv\"\n",
        "MODEL_SAVE_DIR = \"/content/drive/MyDrive/DermAI_FinalTraining_Model\"\n",
        "PLOTS_DIR = \"/content/drive/MyDrive/DermAI_Final_Results_Plots\"\n",
        "\n",
        "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(PLOTS_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8QEbO3ptC2C",
        "outputId": "43225f46-f00a-4a52-87cd-7794fe6ff333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Configuration:\n",
            "  Image Size: (224, 224)\n",
            "  Batch Size: 32\n",
            "  Max Epochs: 50\n",
            "  Model Directory: /content/drive/MyDrive/DermAI_FinalTraining_Model\n"
          ]
        }
      ],
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "random.seed(RANDOM_STATE)\n",
        "\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"  Image Size: {IMG_SIZE}\")\n",
        "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"  Max Epochs: {EPOCHS}\")\n",
        "print(f\"  Model Directory: {MODEL_SAVE_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf8eBnR2tCtr",
        "outputId": "3e893c74-dd49-460b-ccf3-bc2efac30b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total samples: 19,501\n",
            "\n",
            "Class distribution:\n",
            "label\n",
            "benign       13291\n",
            "malignant     6210\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load and Inspect Dataset\n",
        "df = pd.read_csv(METADATA_PATH)\n",
        "print(f\"\\nTotal samples: {len(df):,}\")\n",
        "print(f\"\\nClass distribution:\")\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s9Ul_Mb5tCe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a280ca9e-f707-4e1e-fe07-b92f0cf257c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All image files verified successfully\n"
          ]
        }
      ],
      "source": [
        "# Verify file existence\n",
        "missing_files = []\n",
        "for idx, row in df.iterrows():\n",
        "    if not os.path.exists(row['path']):\n",
        "        missing_files.append(row['path'])\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"\\nWarning: {len(missing_files)} files not found\")\n",
        "else:\n",
        "    print(\"\\nAll image files verified successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OYkbEdgmtgR"
      },
      "source": [
        "##### Data Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4ElEm1IIyYcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67084f39-5938-4be5-faa6-74e1cd8081e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train set: 15,600 samples\n",
            "  Benign: 10,632\n",
            "  Malignant: 4,968\n",
            "\n",
            "Validation set: 1,950 samples\n",
            "  Benign: 1,329\n",
            "  Malignant: 621\n",
            "\n",
            "Test set: 1,951 samples\n",
            "  Benign: 1,330\n",
            "  Malignant: 621\n"
          ]
        }
      ],
      "source": [
        "# Data Split: 80% Train / 10% Val / 10% Test\n",
        "\n",
        "# Load df and prepare X, y for training (these lines are moved/duplicated from _emNvBXnEcr0 for immediate execution)\n",
        "df = pd.read_csv(METADATA_PATH)\n",
        "X = df['path'].values\n",
        "y = df['label_idx'].values\n",
        "\n",
        "# First split: 80% train+val, 20% test\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y, test_size=0.10, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Second split: 80% train, 10% val (from remaining 90%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.1111, stratify=y_temp, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "train_df = pd.DataFrame({'path': X_train, 'label_idx': y_train})\n",
        "val_df = pd.DataFrame({'path': X_val, 'label_idx': y_val})\n",
        "test_df = pd.DataFrame({'path': X_test, 'label_idx': y_test})\n",
        "\n",
        "print(f\"\\nTrain set: {len(train_df):,} samples\")\n",
        "print(f\"  Benign: {(train_df['label_idx']==0).sum():,}\")\n",
        "print(f\"  Malignant: {(train_df['label_idx']==1).sum():,}\")\n",
        "\n",
        "print(f\"\\nValidation set: {len(val_df):,} samples\")\n",
        "print(f\"  Benign: {(val_df['label_idx']==0).sum():,}\")\n",
        "print(f\"  Malignant: {(val_df['label_idx']==1).sum():,}\")\n",
        "\n",
        "print(f\"\\nTest set: {len(test_df):,} samples\")\n",
        "print(f\"  Benign: {(test_df['label_idx']==0).sum():,}\")\n",
        "print(f\"  Malignant: {(test_df['label_idx']==1).sum():,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1qygJ4X3y1Lx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5ff272eb-d357-4502-aab4-e19a78080ff1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABdEAAAGGCAYAAACUkchWAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZmBJREFUeJzt3XlYlPX+//HXsCMwIIoghUhq5m6pEWouJxJLO5m2WFS4pNVBS/0eLTvudbLM3E3TSq2g9ZSVpUmuZai4kIpmapKWAZoBLsl6//7wx50TjCECM+rzcV33dZj78577/txzmnk577nnHothGIYAAAAAAAAAAEApLo6eAAAAAAAAAAAAzoomOgAAAAAAAAAAdtBEBwAAAAAAAADADproAAAAAAAAAADYQRMdAAAAAAAAAAA7aKIDAAAAAAAAAGAHTXQAAAAAAAAAAOygiQ4AAAAAAAAAgB000QEAAAAAAAAAsIMmOuBE+vXrp/r16zt6Gg5Xv3599evXr8r3k56eLovFosWLF5vr+vXrJ19f3yrfdwmLxaIJEyZU2/4AAJWrrCy5nJDJAABceshvoPLRRAfKwWKxlGtZu3ato6daSnp6uvr3768GDRrIy8tLISEh6tSpk8aPH1+h7X3xxRcXFFBdunQxHx8XFxdZrVY1btxYDz30kJKSkio0h8qYV3Vy5rkBwJXkn//8p2rUqKETJ07YrYmNjZWHh4d+++23St8/mex4zjw3ALhSVef77dOnT2vChAkXtC3y2/GceW64clgMwzAcPQnA2b399ts2t998800lJSXprbfesll/6623Kjg4uML7KSgoUHFxsTw9PSu8jXPt379f7dq1k7e3twYMGKD69evr119/1bZt27R8+XKdOXPmgrc5ZMgQzZ07V+V96ejSpYsOHDigyZMnS5JOnTql/fv366OPPtKPP/6oe++9V2+//bbc3d3N++Tl5cnFxcVmXWXPS5IMw1BeXp7c3d3l6uoq6eyn5h9++KFOnjxZ7u1czNzOnDkjNzc3ubm5Vdr+AABle++999S3b18tWbJEDz/8cKnx06dPq06dOvrHP/6hTz/9tFzbTE9PV0REhBYtWnTeM77I5PMjkwHgylVd77cl6dixYwoKCtL48ePL1ZQlv8+P/MaVhP/CgHJ48MEHbW5v3LhRSUlJpdb/1enTp1WjRo1y7+dCAq48pk+frpMnTyo1NVXh4eE2Y1lZWZW6r/Px9/cv9Vi98MILeuKJJ/TKK6+ofv36evHFF82xyvoQwZ7CwkIVFxfLw8NDXl5eVbqvv+Po/QPAleSf//yn/Pz8lJiYWGYT/ZNPPtGpU6cUGxtb6fsmk8tGJgMAKvp+uzqQ32Ujv3El4nIuQCXp0qWLmjdvrq1bt6pTp06qUaOGnnnmGUln35T36NFDoaGh8vT0VIMGDfTss8+qqKjIZht/vSZ6yfXFpk6dqgULFqhBgwby9PRUu3btlJKS8rdzOnDggK6++upSYS9JderUKbVu+fLluvnmm+Xj4yM/Pz/16NFDaWlpNvObO3euJNuv3FWEq6urZs2apaZNm2rOnDnKyckxx/56/baCggJNnDhRjRo1kpeXl2rVqqWOHTuaX10737zOfQxnzJhhPoa7d+8+73Vsf/zxR8XExMjHx0ehoaGaNGmSzafea9euLfMrhX/d5t89ZmVdv2379u267bbbZLVa5evrq1tuuUUbN260qVm8eLEsFos2bNigESNGKCgoSD4+Prrrrrt09OjRv/8/AACuQN7e3urdu7dWrVpV5hvfxMRE+fn56Z///KeOHz+uf//732rRooV8fX1ltVp122236bvvvqvQvslkMhkAUHHFxcWaMWOGmjVrJi8vLwUHB+vRRx/V77//blO3ZcsWxcTEqHbt2vL29lZERIQGDBgg6WwuBAUFSZImTpxo5sD5zkgnv8lvoARNdKAS/fbbb7rtttvUunVrzZgxQ127dpV09sXZ19dXI0aM0MyZM9WmTRuNGzdOTz/9dLm2m5iYqJdeekmPPvqonnvuOaWnp6t3794qKCg47/3Cw8N1+PBhrV69+m/38dZbb6lHjx7y9fXViy++qLFjx2r37t3q2LGj0tPTJUmPPvqobr31VrO+ZKkoV1dX3X///Tp9+rS++eYbu3UTJkzQxIkT1bVrV82ZM0f/+c9/VK9ePW3btq3c81q0aJFmz56twYMH6+WXX1ZgYKDd/RUVFal79+4KDg7WlClT1KZNG40fP75C17y70McsLS1NN998s7777juNGjVKY8eO1cGDB9WlSxdt2rSpVP3QoUP13Xffafz48Xr88cf12WefaciQIRc8TwC4GOvXr9ftt9+uoKAg843N/PnzbWoGDBigRo0aydfXVz4+PmrQoIGeeOIJHT9+3Kz55ptv1LdvXzVo0EA+Pj7mG7ylS5fabKugoEAzZsxQixYt5OPjo9q1ays2NlY///zz3841NjZWhYWFev/9923WHz9+XF9++aXuuusueXt768cff9TSpUvVs2dPTZs2TSNHjtTOnTvVuXNnHTly5IIfIzL5T2QyADhGZeX1d999p+joaIWEhMjDw0O1atVSZGSk3njjjVL7fPfdd3XDDTfI29tbgYGBuvvuu3XgwIELnvujjz6qkSNHqkOHDpo5c6b69++vhIQExcTEmO+Ls7Ky1K1bN6Wnp+vpp5/W7NmzFRsbazZPg4KCNG/ePEnSXXfdZeZA79697e6X/P4T+Y0rngHggsXHxxt/ffp07tzZkGTMnz+/VP3p06dLrXv00UeNGjVqGGfOnDHXxcXFGeHh4ebtgwcPGpKMWrVqGcePHzfXf/LJJ4Yk47PPPjvvPHft2mV4e3sbkozWrVsbTz75pLF06VLj1KlTNnUnTpwwAgICjEGDBtmsz8jIMPz9/W3Wl3Xs59O5c2ejWbNmdsc//vhjQ5Ixc+ZMc114eLgRFxdn3m7VqpXRo0eP8+7H3rxKHkOr1WpkZWWVObZo0SJzXVxcnCHJGDp0qLmuuLjY6NGjh+Hh4WEcPXrUMAzDWLNmjSHJWLNmzd9u83yPmSRj/Pjx5u1evXoZHh4exoEDB8x1R44cMfz8/IxOnTqZ6xYtWmRIMqKjo43i4mJz/fDhww1XV1cjOzu7zP0BQFWYPn264ebmZlx77bWGJEOSMW/ePJuawMBAIyIiwmjTpo1Rr149sy4mJsasGT9+vCHJqFOnjtGyZUvD3d3drHvvvffMupLXaklGs2bNjFq1ahmSjPDw8L99/SssLDTq1q1rREVF2ayfP3++Icn48ssvDcMwjDNnzhhFRUU2NQcPHjQ8PT2NSZMm2az76+t+WchkMhkAHK2y8vrjjz82fH19jSZNmhg33HCD4efnZ9a98847Zt1rr71mro+IiDCsVquZ87/++qvdef71tfrrr782JBkJCQk2dStWrLBZX5JjKSkpdrd99OjRUq/350N+k99ACc5EByqRp6en+vfvX2q9t7e3+feJEyd07Ngx3XzzzTp9+rS+//77v93ufffdp5o1a5q3b775Zklnvx51Ps2aNVNqaqoefPBBpaena+bMmerVq5eCg4O1cOFCsy4pKUnZ2dm6//77dezYMXNxdXVVZGSk1qxZ87dzrChfX19JZx8XewICApSWlqZ9+/ZVeD99+vQxv7pXHud+8myxWDRkyBDl5+frq6++qvAc/k5RUZFWrlypXr166ZprrjHX161bVw888IC++eYb5ebm2txn8ODBNl9lu/nmm1VUVKSffvqpyuYJAH/10EMPKTc3V19++aXdml9++UU//vijtmzZop9++kkdO3aUJG3YsMGsad68uVauXKnMzEx999132rhxo1xczv5zNSEhQdLZvCg5++jf//63du3apf3798vHx0c//fST+XVfe1xdXdW3b18lJyebZ4VJZ7/1FRwcrFtuuUXS2Uwv2XdRUZF+++03+fr6qnHjxuZZWxeCTP4TmQwAjlFZeX377bcrNzdXu3fv1tatW7V9+3ZzrKQuPz/f/OZ1nz599OOPP2rPnj3y8/NTVlaWnn/++XLP+4MPPpC/v79uvfVWm2xs06aNfH19zWwMCAiQJC1btuxvv7VdXuT3n8hvXOloogOV6KqrrpKHh0ep9Wlpabrrrrvk7+8vq9WqoKAg80dBzr1umT316tWzuV3SUP/r9d/Kcu211+qtt97SsWPHtGPHDj3//PNyc3PT4MGDzfAqCdJ//OMfCgoKsllWrlxZpT+YUvKL3X5+fnZrJk2apOzsbF177bVq0aKFRo4cqR07dlzQfiIiIspd6+LiYhO40tnHUZJNw6WyHT16VKdPn1bjxo1LjTVp0kTFxcU6fPiwzfqL+W8DACpLrVq1bD4wLouXl5fGjh2ryMhI1a9f3/zKccmbc0m6++67za/rStL1119v5kPJD2QZhmFeT7OkyX3uG5/yvDEr+eHQxMRESdLPP/+sr7/+Wn379pWrq6uks9denT59uho1aiRPT0/Vrl1bQUFB2rFjR7myuyxk8llkMgA4RmXltYeHhwoKCnTTTTepTZs2uuGGG8yxkrqUlBQdO3ZM0tnmqySFhobqpptukiStWLGi3PPet2+fcnJyVKdOnVLZePLkSTMbO3furD59+mjixImqXbu27rzzTi1atEh5eXnl3ldZyO+zyG9c6dwcPQHgclLWP0iys7PVuXNnWa1WTZo0SQ0aNJCXl5e2bdump556SsXFxX+73ZI39H9V0kQoD1dXV7Vo0UItWrRQVFSUunbtqoSEBEVHR5tzeOuttxQSElLqvm5uVfdSsWvXLklSw4YN7dZ06tRJBw4c0CeffKKVK1fqtdde0/Tp0zV//nw98sgj5drP3/1j8ULZ+/GXv/5YbFWrjP82AKC67Nu3T5s3bzZvR0dHl7o2+bkSEhKUk5Mji8Vivt5brVZ1795dy5cv15QpU/TFF18oIyNDp06dknT2DLq/06ZNG1133XV655139Mwzz+idd96RYRhmc12Snn/+eY0dO1YDBgzQs88+q8DAQLm4uGjYsGHlyu7zIZPJZABwZuXJ6+LiYpvrS7u5uenll1/WfffdJ0k2jcpzf4AzODhYknTo0KFyz6e4uFh16tQxv5X2VyVnR1ssFn344YfauHGjPvvsM3355ZcaMGCAXn75ZW3cuNE8Y7uiyG/yG1c2muhAFVu7dq1+++03ffTRR+rUqZO5/uDBgw6bU9u2bSVJv/76qySpQYMGks7+4yY6Ovq8963oL4eXpaioSImJiapRo4bNmQ1lCQwMVP/+/dW/f3+dPHlSnTp10oQJE8zAr8x5FRcX68cffzQ/KZekH374QdLZXzmX/vx0Ojs72+a+ZX3lq7xzCwoKUo0aNbR3795SY99//71cXFwUFhZWrm0BgDN699139dZbbyktLU0PPfSQvvrqK8XHx+vNN98sVfvGG2/o0UcflSRNnTpV3bp1M8cSEhI0ZswYffrpp/rxxx/Vtm1bnT59Wlu2bJG7u3u55hIbG6uxY8dqx44dSkxMVKNGjdSuXTtz/MMPP1TXrl31+uuv29wvOztbtWvXrsjhl4lMPj8yGQCqX3ny2svLS4Zh6MSJE/roo480cOBAjRo1Sg0bNtTtt99ud9sVaUw2aNBAX331lTp06FCuRu5NN92km266Sf/973+VmJio2NhYvfvuu3rkkUcqLaPI7/Mjv3E54nIuQBUr+VTz3H8s5Ofn65VXXqnyfX/99ddlXgvuiy++kCTzK04xMTGyWq16/vnny6w/evSo+bePj4+k0kF3oYqKivTEE09oz549euKJJ2S1Wu3W/vbbbza3fX191bBhQ5uv5VXWvErMmTPH/NswDM2ZM0fu7u7mtXLDw8Pl6uqq9evX29yvrP9fyzs3V1dXdevWTZ988onNV9wyMzOVmJiojh07nvdxAoBLgbu7u1q3bq1BgwZJOnvGVsmbKunsa+6YMWM0cOBAWSwWvfHGGxoxYoTNNmrWrKm5c+fq8OHDOnXqlNauXWteB7Ssr++WpeSs83Hjxik1NdXmLHTp7GvyX9/of/DBB+U6070sZHLFkckAUP3+Lq9L+Pn5KS4uTi1btlReXp6ee+45SbJpVJ57KZOSv/96CY3zuffee1VUVKRnn3221FhhYaH5mv7777+Xyu7WrVtLkplTNWrUkFT+jCK/K478xuWGM9GBKta+fXvVrFlTcXFxeuKJJ2SxWPTWW29Vy1eDXnzxRW3dulW9e/dWy5YtJUnbtm3Tm2++qcDAQA0bNkzS2a/Gz5s3Tw899JBuuOEG9e3bV0FBQTp06JA+//xzdejQwQzANm3aSJKeeOIJxcTEmD/Qdj45OTl6++23JUmnT5/W/v379dFHH+nAgQPq27dvmf8YOlfTpk3VpUsXtWnTRoGBgdqyZYs+/PBDmx8qqci87PHy8tKKFSsUFxenyMhILV++XJ9//rmeeeYZ86uC/v7+uueeezR79mxZLBY1aNBAy5YtK/Nadxcyt+eee05JSUnq2LGj/vWvf8nNzU2vvvqq8vLyNGXKlAodDwA4WkpKik6dOqUuXbpIUqkflSq5FEt+fr769++vxMRE+fv768MPPyzzbK7du3eb1xmVpJdeesk846i8r/0RERFq3769PvnkE0kq1UTv2bOnJk2apP79+6t9+/bauXOnEhISSl3fs7zIZDIZAJxdefM6ISFBXbp00VVXXSXp7BnG+/fvt6lp166datWqpd9++03/+9//dP/99+vIkSPauHGjJKl79+7lnlfnzp316KOPavLkyUpNTVW3bt3k7u6uffv26YMPPtDMmTN19913a8mSJXrllVd01113qUGDBjpx4oQWLlwoq9Vqnh3v7e2tpk2b6r333tO1116rwMBANW/eXM2bNy9z3+Q3+Q2YDAAXLD4+3vjr06dz585Gs2bNyqzfsGGDcdNNNxne3t5GaGioMWrUKOPLL780JBlr1qwx6+Li4ozw8HDz9sGDBw1JxksvvVRqm5KM8ePHn3eeGzZsMOLj443mzZsb/v7+hru7u1GvXj2jX79+xoEDB0rVr1mzxoiJiTH8/f0NLy8vo0GDBka/fv2MLVu2mDWFhYXG0KFDjaCgIMNisZR6HP6qc+fOhiRz8fX1NRo1amQ8+OCDxsqVK8u8T3h4uBEXF2fefu6554wbb7zRCAgIMLy9vY3rrrvO+O9//2vk5+f/7bzO9xiWjC1atMhcFxcXZ/j4+BgHDhwwunXrZtSoUcMIDg42xo8fbxQVFdnc/+jRo0afPn2MGjVqGDVr1jQeffRRY9euXaW2eb7HrKz/H7dt22bExMQYvr6+Ro0aNYyuXbsa3377rU3NokWLDElGSkqKzfo1a9aU+u8KAKra//73P6NBgwZGeHi4+XofFBRkNGjQwHjggQfM16yaNWsarVq1MgIDA8261q1bm6+vzz//vLn+qquuMiIjI82lV69e5v5eeuklw93d3WjSpIkRGhpq3ueuu+4yiouLyz3vuXPnGpKMG2+8sdTYmTNnjP/7v/8z6tata3h7exsdOnQwkpOTjc6dOxudO3c268rKkrKQyWQyADhaZeV1586dDYvFYoSHhxvNmzc33NzczLqXX37Z3N+rr75qro+IiDCsVqshyahdu7bxyy+/2J1nWe+3DcMwFixYYLRp08bw9vY2/Pz8jBYtWhijRo0yjhw5YhjG2dfs+++/36hXr57h6elp1KlTx+jZs6dNdhqGYXz77bdGmzZtDA8Pj799X01+k99ACYthcKV8AAAAVNzixYvVv3//Msc6d+6sqVOnauzYsfruu+907Ngxubq6KiIiQj169NAzzzxjXhNzwoQJmjhxYpnbCQ8PN7+Wu2LFCj3zzDPav3+/8vLy1KhRI8XFxWn48OFV+sNdAABcyiorr6dPn66EhAQdOHBAJ06ckJ+fn1q2bKlBgwbpwQcftNluQkKCpk6dqj179sjLy0u33HKLXnjhBTVq1KjKjxcAKhNNdAAAAAAAAAAA7OCHRQEAAAAAAAAAsIMmOgAAAAAAAAAAdtBEBwAAAAAAAADADproAAAAAAAAAADYQRMdAAAAAAAAAAA73Bw9gctFcXGxjhw5Ij8/P1ksFkdPBwBwGTMMQydOnFBoaKhcXPg8/EKQ1wCA6kJeVxx5DQCoLuXNa5roleTIkSMKCwtz9DQAAFeQw4cP6+qrr3b0NC4p5DUAoLqR1xeOvAYAVLe/y2ua6JXEz89P0tkH3Gq1Ong2AIDLWW5ursLCwszsQfmR1wCA6kJeVxx5DQCoLuXNa5rolaTkK2ZWq5WQBwBUC77efOHIawBAdSOvLxx5DQCobn+X11yYDU5j/fr1uv322xUUFCSLxSKLxaL58+fb1BQUFGjixIm65ppr5OHhoauvvlrDhw/XyZMnS23vtddeU7t27eTj4yNfX181b95cixYtMsdnzJihVq1aKSAgQJ6enrr66qt1zz33aMeOHWbNzz//rMcee0wtWrRQzZo1ze1MnTpVBQUFVfdgAAAAAAAAAHAKNNHhNLZt26akpCQFBgbarRkwYIAmTJign376Sddcc42ysrI0Y8YM9ezZU8XFxWbd0KFDNWjQIG3ZskW1a9dWo0aNdPToUW3YsMGsWbdunY4ePaprrrlGDRo00K+//qoPP/xQXbt21alTpyRJ+/fv16uvvqr09HTVr19frq6uSktL08iRI/Xkk09W3YMBAAAAAAAAwCnQRIfTeOihh5Sbm6svv/yyzPFt27bp7bffliTNnDlT33//vf73v/9JOtsQX7p0qSQpOTlZc+bMkYuLiz766CP99NNP2r59uzIzMzV9+nRze++8846OHDmibdu2affu3XrmmWckScePH9f3338vSQoMDNTChQt17Ngxbd++Xenp6YqIiJAkJSQkVMnjAAAAAAAAAMB50ESH06hVq5a8vb3tji9fvtz8u0+fPpKkHj16yMvLS5K0YsUKSdL7778vSbrqqqv0xhtvyN/fX/Xq1dPQoUNlGIa5DS8vL3388ce66aab1LRpUz3//POSpKCgIF177bWSpJYtW+qRRx6Rp6enJKlmzZpq3ry5JJnrAAAAAAAAAFy++GFRXDIOHz5s/l2nTh1JkouLi2rXrq2ff/5Zhw4dkiTt3bvXrD927JiuueYa7d69W3PmzFF6ero+++wzczuZmZnatGmTeTsiIkKfffaZ3V/k3bt3r1avXi1JGjRoUOUeIAAAAAAAAACnw5nouOSde3a5JBUWFpp/r1y5Urt27dLEiRMlScuWLVN6ero5/thjj6m4uFg//fST7rvvPh08eFD33XefTpw4UWo/KSkp6ty5s06dOqXevXub2wQAAAAAAABw+aKJjktGWFiY+XdWVpYkqbi4WL/99pskqV69epLOXsalRLt27SRJN954o7nu3Ca6JFksFtWrV8+8JnpaWpreeecdm5pPPvlEXbp0UWZmpgYPHqz3339fbm58kQMAAAAAAAC43NFExyWje/fu5t8lPyj6+eef68yZMzbj0dHRZt2WLVts/tdisahhw4b67bff9NZbbyk/P9+s/eKLL8y/T506Zf49c+ZM9e7dW3/88YdefPFFvfrqq3J1da3swwMAAAAAAADghCzGX6+FgQrJzc2Vv7+/cnJyZLVaHT2dS9JHH32kUaNGqbCwUD/99JOksz/yabVaFRkZqYSEBD3wwAN655135OLiomuvvVYHDhxQQUGBbr75Zq1du1YuLi4qKChQ+/bttWXLFtWoUUPXXHON0tLSZBiGBgwYoNdff13p6emKiIiQt7e3GjRooJycHPOa635+ftq5c6fCw8OVnJys9u3bm+ubNm1qM+ePP/5YdevWrd4HCsAVj8ypOB47AEB1IXMqjscOAFBdyps5XI8CTiM3N1cHDhywWXf06FEdPXpUV199tSRpyZIlatSokd58800dOHBAQUFBuvvuu/Xcc8/JxeXsFyvc3d21cuVKjR49Wp988on279+vZs2a6ZFHHtGQIUMkSQEBAerbt682b95sNuLDwsLUuXNnPfPMMwoPD5ck5eXlmXM5ceKEzY+Q/nUcAAAAAAAAwOWHM9ErCZ+UAwCqC5lTcTx2AIDqQuZUHI8dAKC6lDdzuCY6AAAAAAAAAAB20EQHAAAAAAAAAMAOronupF7YfszRUwDK9PT1tR09BQBwGuQ1nBV5DQB/Iq/hrMhr4NLBmegAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDgAAAAAAAACAHTTRAQAAAAAAAACwgyY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDgAAAAAAAACAHQ5toq9fv1533HGHQkNDZbFYtHTpUptxwzA0btw41a1bV97e3oqOjta+fftsao4fP67Y2FhZrVYFBARo4MCBOnnypE3Njh07dPPNN8vLy0thYWGaMmVKqbl88MEHuu666+Tl5aUWLVroiy++qPTjBQAAAAAAAABcWhzaRD916pRatWqluXPnljk+ZcoUzZo1S/Pnz9emTZvk4+OjmJgYnTlzxqyJjY1VWlqakpKStGzZMq1fv16DBw82x3Nzc9WtWzeFh4dr69ateumllzRhwgQtWLDArPn22291//33a+DAgdq+fbt69eqlXr16adeuXVV38AAAAAAAAAAAp+fmyJ3fdtttuu2228ocMwxDM2bM0JgxY3TnnXdKkt58800FBwdr6dKl6tu3r/bs2aMVK1YoJSVFbdu2lSTNnj1bt99+u6ZOnarQ0FAlJCQoPz9fb7zxhjw8PNSsWTOlpqZq2rRpZrN95syZ6t69u0aOHClJevbZZ5WUlKQ5c+Zo/vz51fBIAAAAAAAAAACckdNeE/3gwYPKyMhQdHS0uc7f31+RkZFKTk6WJCUnJysgIMBsoEtSdHS0XFxctGnTJrOmU6dO8vDwMGtiYmK0d+9e/f7772bNufspqSnZT1ny8vKUm5trswAAAAAAAAAALi9O20TPyMiQJAUHB9usDw4ONscyMjJUp04dm3E3NzcFBgba1JS1jXP3Ya+mZLwskydPlr+/v7mEhYVd6CECAAAAAAAAAJyc0zbRnd3o0aOVk5NjLocPH3b0lAAAAAAAAAAAlcxpm+ghISGSpMzMTJv1mZmZ5lhISIiysrJsxgsLC3X8+HGbmrK2ce4+7NWUjJfF09NTVqvVZgEAAAAAAAAAXF6ctokeERGhkJAQrVq1ylyXm5urTZs2KSoqSpIUFRWl7Oxsbd261axZvXq1iouLFRkZadasX79eBQUFZk1SUpIaN26smjVrmjXn7qekpmQ/AAAAAAAAAIArk0Ob6CdPnlRqaqpSU1Mlnf0x0dTUVB06dEgWi0XDhg3Tc889p08//VQ7d+7Uww8/rNDQUPXq1UuS1KRJE3Xv3l2DBg3S5s2btWHDBg0ZMkR9+/ZVaGioJOmBBx6Qh4eHBg4cqLS0NL333nuaOXOmRowYYc7jySef1IoVK/Tyyy/r+++/14QJE7RlyxYNGTKkuh8SAAAAAAAAAIATcXPkzrds2aKuXbuat0sa23FxcVq8eLFGjRqlU6dOafDgwcrOzlbHjh21YsUKeXl5mfdJSEjQkCFDdMstt8jFxUV9+vTRrFmzzHF/f3+tXLlS8fHxatOmjWrXrq1x48Zp8ODBZk379u2VmJioMWPG6JlnnlGjRo20dOlSNW/evBoeBQAAAAAAAACAs3JoE71Lly4yDMPuuMVi0aRJkzRp0iS7NYGBgUpMTDzvflq2bKmvv/76vDX33HOP7rnnnvNPGAAAAAAAAABwRXHaa6IDAIBLx/r163XHHXcoNDRUFotFS5cuNccKCgr01FNPqUWLFvLx8VFoaKgefvhhHTlyxGYbx48fV2xsrKxWqwICAjRw4ECdPHnSpmbHjh26+eab5eXlpbCwME2ZMqU6Dg8AgMsCeQ0AQMXQRAcAABft1KlTatWqlebOnVtq7PTp09q2bZvGjh2rbdu26aOPPtLevXv1z3/+06YuNjZWaWlpSkpK0rJly7R+/Xqby6/l5uaqW7duCg8P19atW/XSSy9pwoQJWrBgQZUfHwAAlwPyGgCAinHo5VwAAMDl4bbbbtNtt91W5pi/v7+SkpJs1s2ZM0c33nijDh06pHr16mnPnj1asWKFUlJS1LZtW0nS7Nmzdfvtt2vq1KkKDQ1VQkKC8vPz9cYbb8jDw0PNmjVTamqqpk2bZvPmHQAAlI28BgCgYjgTHQAAVLucnBxZLBYFBARIkpKTkxUQEGC+IZek6Ohoubi4aNOmTWZNp06d5OHhYdbExMRo7969+v3336t1/gAAXAnIawAAzuJMdAAAUK3OnDmjp556Svfff7+sVqskKSMjQ3Xq1LGpc3NzU2BgoDIyMsyaiIgIm5rg4GBzrGbNmqX2lZeXp7y8PPN2bm5upR4LAACXK/IaAIA/cSY6AACoNgUFBbr33ntlGIbmzZtX5fubPHmy/P39zSUsLKzK9wkAwKWOvAYAwBZNdAAAUC1K3pD/9NNPSkpKMs9qk6SQkBBlZWXZ1BcWFur48eMKCQkxazIzM21qSm6X1PzV6NGjlZOTYy6HDx+uzEMCAOCyQ14DAFAaTXQAAFDlSt6Q79u3T1999ZVq1aplMx4VFaXs7Gxt3brVXLd69WoVFxcrMjLSrFm/fr0KCgrMmqSkJDVu3LjMr4ZLkqenp6xWq80CAADKRl4DAFA2mugAAOCinTx5UqmpqUpNTZUkHTx4UKmpqTp06JAKCgp09913a8uWLUpISFBRUZEyMjKUkZGh/Px8SVKTJk3UvXt3DRo0SJs3b9aGDRs0ZMgQ9e3bV6GhoZKkBx54QB4eHho4cKDS0tL03nvvaebMmRoxYoSjDhsAgEsKeQ0AQMXww6IAAOCibdmyRV27djVvl7xRjouL04QJE/Tpp59Kklq3bm1zvzVr1qhLly6SpISEBA0ZMkS33HKLXFxc1KdPH82aNcus9ff318qVKxUfH682bdqodu3aGjdunAYPHly1BwcAwGWCvAYAoGJoogMAgIvWpUsXGYZhd/x8YyUCAwOVmJh43pqWLVvq66+/vuD5AQAA8hoAgIrici4AAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDgAAAAAAAACAHTTRAQAAAAAAAACwgyY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDgAAAAAAAACAHTTRAQAAAAAAAACwgyY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDgAAAAAAAACAHTTRAQAAAAAAAACwgyY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7KCJDgAAAAAAAACAHTTRAQAAAAAAAACwgyY6AAAAAAAAAAB20EQHAAAAAAAAAMAOmugAAAAAAAAAANhBEx0AAAAAAAAAADtoogMAAAAAAAAAYAdNdAAAAAAAAAAA7HDqJnpRUZHGjh2riIgIeXt7q0GDBnr22WdlGIZZYxiGxo0bp7p168rb21vR0dHat2+fzXaOHz+u2NhYWa1WBQQEaODAgTp58qRNzY4dO3TzzTfLy8tLYWFhmjJlSrUcIwAAl4P169frjjvuUGhoqCwWi5YuXWozTl4DAOB45DUAABXj1E30F198UfPmzdOcOXO0Z88evfjii5oyZYpmz55t1kyZMkWzZs3S/PnztWnTJvn4+CgmJkZnzpwxa2JjY5WWlqakpCQtW7ZM69ev1+DBg83x3NxcdevWTeHh4dq6dateeuklTZgwQQsWLKjW4wUA4FJ16tQptWrVSnPnzi1znLwGAMDxyGsAACrGYpx7WreT6dmzp4KDg/X666+b6/r06SNvb2+9/fbbMgxDoaGh+r//+z/9+9//liTl5OQoODhYixcvVt++fbVnzx41bdpUKSkpatu2rSRpxYoVuv322/Xzzz8rNDRU8+bN03/+8x9lZGTIw8NDkvT0009r6dKl+v7778s119zcXPn7+ysnJ0dWq/Wij/2F7ccuehtAVXj6+tqOngJwxavszKlsFotFH3/8sXr16iVJ5DXgAOQ14HjkNXkN/B3yGnC88maOU5+J3r59e61atUo//PCDJOm7777TN998o9tuu02SdPDgQWVkZCg6Otq8j7+/vyIjI5WcnCxJSk5OVkBAgBnwkhQdHS0XFxdt2rTJrOnUqZMZ8JIUExOjvXv36vfffy9zbnl5ecrNzbVZAABAaeQ1AADOj7wGAMA+p26iP/300+rbt6+uu+46ubu76/rrr9ewYcMUGxsrScrIyJAkBQcH29wvODjYHMvIyFCdOnVsxt3c3BQYGGhTU9Y2zt3HX02ePFn+/v7mEhYWdpFHCwDA5Ym8BgDA+ZHXAADY59RN9Pfff18JCQlKTEzUtm3btGTJEk2dOlVLlixx9NQ0evRo5eTkmMvhw4cdPSUAAPAX5DUAAM6PvAYAODs3R0/gfEaOHGmejS5JLVq00E8//aTJkycrLi5OISEhkqTMzEzVrVvXvF9mZqZat24tSQoJCVFWVpbNdgsLC3X8+HHz/iEhIcrMzLSpKbldUvNXnp6e8vT0vPiDBADgMkdeAwDg/MhrAADsc+oz0U+fPi0XF9spurq6qri4WJIUERGhkJAQrVq1yhzPzc3Vpk2bFBUVJUmKiopSdna2tm7datasXr1axcXFioyMNGvWr1+vgoICsyYpKUmNGzdWzZo1q+z4AAC4EpDXAAA4P/IaAAD7nLqJfscdd+i///2vPv/8c6Wnp+vjjz/WtGnTdNddd0k6+2viw4YN03PPPadPP/1UO3fu1MMPP6zQ0FDzF8abNGmi7t27a9CgQdq8ebM2bNigIUOGqG/fvgoNDZUkPfDAA/Lw8NDAgQOVlpam9957TzNnztSIESMcdegAAFxSTp48qdTUVKWmpko6++NkqampOnToEHkNAICTIK8BAKgYp76cy+zZszV27Fj961//UlZWlkJDQ/Xoo49q3LhxZs2oUaN06tQpDR48WNnZ2erYsaNWrFghLy8vsyYhIUFDhgzRLbfcIhcXF/Xp00ezZs0yx/39/bVy5UrFx8erTZs2ql27tsaNG6fBgwdX6/ECAHCp2rJli7p27WreLnmjHBcXp8WLF5PXAAA4AfIaAICKsRiGYTh6EpeD3Nxc+fv7KycnR1ar9aK398L2Y5UwK6DyPX19bUdPAbjiVXbmXEnIa1wpyGvA8cjriiOvcaUgrwHHK2/mOPXlXAAAAAAAAAAAcCSa6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwCAKldUVKSxY8cqIiJC3t7eatCggZ599lkZhmHWGIahcePGqW7duvL29lZ0dLT27dtns53jx48rNjZWVqtVAQEBGjhwoE6ePFndhwMAwGWJvAYAoGw00QEAQJV78cUXNW/ePM2ZM0d79uzRiy++qClTpmj27NlmzZQpUzRr1izNnz9fmzZtko+Pj2JiYnTmzBmzJjY2VmlpaUpKStKyZcu0fv16DR482BGHBADAZYe8BgCgbG6OngAAALj8ffvtt7rzzjvVo0cPSVL9+vX1zjvvaPPmzZLOntU2Y8YMjRkzRnfeeack6c0331RwcLCWLl2qvn37as+ePVqxYoVSUlLUtm1bSdLs2bN1++23a+rUqQoNDXXMwQEAcJkgrwEAKBtnogMAgCrXvn17rVq1Sj/88IMk6bvvvtM333yj2267TZJ08OBBZWRkKDo62ryPv7+/IiMjlZycLElKTk5WQECA+YZckqKjo+Xi4qJNmzZV49EAAHB5Iq8BACgbZ6IDAIAq9/TTTys3N1fXXXedXF1dVVRUpP/+97+KjY2VJGVkZEiSgoODbe4XHBxsjmVkZKhOnTo2425ubgoMDDRr/iovL095eXnm7dzc3Eo7JgAALjfkNQAAZeNMdAAAUOXef/99JSQkKDExUdu2bdOSJUs0depULVmypEr3O3nyZPn7+5tLWFhYle4PAIBLGXkNAEDZaKIDAIAqN3LkSD399NPq27evWrRooYceekjDhw/X5MmTJUkhISGSpMzMTJv7ZWZmmmMhISHKysqyGS8sLNTx48fNmr8aPXq0cnJyzOXw4cOVfWgAAFw2yGsAAMpGEx0AAFS506dPy8XF9p8drq6uKi4uliRFREQoJCREq1atMsdzc3O1adMmRUVFSZKioqKUnZ2trVu3mjWrV69WcXGxIiMjy9yvp6enrFarzQIAAMpGXgMAUDauiQ4AAKrcHXfcof/+97+qV6+emjVrpu3bt2vatGkaMGCAJMlisWjYsGF67rnn1KhRI0VERGjs2LEKDQ1Vr169JElNmjRR9+7dNWjQIM2fP18FBQUaMmSI+vbtq9DQUAceHQAAlwfyGgCAstFEBwAAVW727NkaO3as/vWvfykrK0uhoaF69NFHNW7cOLNm1KhROnXqlAYPHqzs7Gx17NhRK1askJeXl1mTkJCgIUOG6JZbbpGLi4v69OmjWbNmOeKQAAC47JDXAACUzWIYhnGhd7rmmmuUkpKiWrVq2azPzs7WDTfcoB9//LHSJnipyM3Nlb+/v3Jycirlq2cvbD9WCbMCKt/T19d29BSAK15lZs6VlunkNa4U5DXgeOR1xZHXuFKQ14DjlTdzKnRN9PT0dBUVFZVan5eXp19++aUimwQAAA5ApgMA4PzIawAAHOuCLufy6aefmn9/+eWX8vf3N28XFRVp1apVql+/fqVNTpJ++eUXPfXUU1q+fLlOnz6thg0batGiRWrbtq0kyTAMjR8/XgsXLlR2drY6dOigefPmqVGjRuY2jh8/rqFDh+qzzz4zv0o2c+ZM+fr6mjU7duxQfHy8UlJSFBQUpKFDh2rUqFGVeiwAADgLR2Q6AAC4MOQ1AADO4YKa6CU/FGKxWBQXF2cz5u7urvr16+vll1+utMn9/vvv6tChg7p27arly5crKChI+/btU82aNc2aKVOmaNasWVqyZIn5oyYxMTHavXu3eU222NhY/frrr0pKSlJBQYH69++vwYMHKzExUdLZ0/a7deum6OhozZ8/Xzt37tSAAQMUEBCgwYMHV9rxAADgLKo70wEAF+bo0aOaNGmSPv30U/3666+yWq1q1aqVFi5cKA8PDz333HPasGGDfv75ZxUUFKh+/frq16+fnnzySbm7u0uSzpw5o8GDB2vz5s364YcfZBiGIiMjtXHjRgcfHcqLvAYA50ZeXzkuqIleXFwsSYqIiFBKSopq167aaze9+OKLCgsL06JFi8x1ERER5t+GYWjGjBkaM2aM7rzzTknSm2++qeDgYC1dulR9+/bVnj17tGLFCqWkpJhnr8+ePVu33367pk6dqtDQUCUkJCg/P19vvPGGPDw81KxZM6WmpmratGk00QEAl6XqznQAQPkdO3ZMkZGROnjwoDw8PHTttdfKMAwlJyfryJEjKiws1KuvvipfX181bNhQP/74o9LS0jRy5Ej9+OOPeuWVVySdfVP+1ltv6aqrrpLValVOTo6DjwwXirwGAOdFXl9ZKnRN9IMHD1ZLeH/66adq27at7rnnHtWpU0fXX3+9Fi5caDOPjIwMRUdHm+v8/f0VGRmp5ORkSVJycrICAgLMBrokRUdHy8XFRZs2bTJrOnXqJA8PD7MmJiZGe/fu1e+//17m3PLy8pSbm2uzAABwqamuTAcAlN+YMWN08OBBNWvWTOnp6dq1a5fS0tKUnZ2tdu3aKTAwUAsXLtSxY8e0fft2paenmycbJSQkmNvx8/PTkSNH9PPPP6t169YOOhpUBvIaAJwPeX1luaAz0c+1atUqrVq1SllZWean4yXeeOONi56YJP3444+aN2+eRowYoWeeeUYpKSl64okn5OHhobi4OGVkZEiSgoODbe4XHBxsjmVkZKhOnTo2425ubgoMDLSpOfcM93O3mZGRYXP5mBKTJ0/WxIkTK+U4AQBwpOrIdABA+RiGoffff1+SFBYWpltvvVUHDx5Uw4YN9fTTT+v+++9Xy5Yt1bJlS/M+NWvWVPPmzXXw4EF5enqa611dXVW3bt1qPwZUDfIaAJwHeX3lqVATfeLEiZo0aZLatm2runXrymKxVPa8JJ396lrbtm31/PPPS5Kuv/567dq1S/Pnzy91PbjqNnr0aI0YMcK8nZubq7CwMAfOCACAC1ddmQ4AKJ+jR4+a34ZdsWKFrrrqKtWsWVM7duzQAw88IHd3d919990299m7d69Wr14tSRo0aFC1zxlVj7wGAOdCXl95KtREnz9/vhYvXqyHHnqosudjo27dumratKnNuiZNmuh///ufJCkkJESSlJmZafOJTWZmpvn1h5CQEGVlZdlso7CwUMePHzfvHxISoszMTJuaktslNX/l6elp86kRAACXourKdABA+RQWFpp/N2nSRKmpqZKk1q1ba8+ePZozZ47Nm/KUlBTdcccdOnXqlHr37s23ZS9T5DUAOBfy+spToWui5+fnq3379pU9l1I6dOigvXv32qz74YcfFB4eLunsj6uEhIRo1apV5nhubq42bdqkqKgoSVJUVJSys7O1detWs2b16tUqLi5WZGSkWbN+/XoVFBSYNUlJSWrcuHGZl3IBAOByUV2ZDgAon6CgIPO3mlq1aiUPDw95eHioVatWkqT09HSz9pNPPlGXLl2UmZmpwYMH6/3335ebW4Wv2AknRl4DgHMhr688FWqiP/LII0pMTKzsuZQyfPhwbdy4Uc8//7z279+vxMRELViwQPHx8ZIki8WiYcOG6bnnntOnn36qnTt36uGHH1ZoaKh69eol6eynQd27d9egQYO0efNmbdiwQUOGDFHfvn0VGhoqSXrggQfk4eGhgQMHKi0tTe+9955mzpxpc7kWAAAuR9WV6QCA8nF3d1enTp0kSTt27FBBQYEKCgq0Y8cOSVKjRo0kSTNnzlTv3r31xx9/6MUXX9Srr74qV1dXh80bVYu8BgDnQl5feSyGYRgXeqcnn3xSb775pnmBfHd3d5vxadOmVdoEly1bptGjR2vfvn2KiIjQiBEjbK4bZBiGxo8frwULFig7O1sdO3bUK6+8omuvvdasOX78uIYMGaLPPvtMLi4u6tOnj2bNmiVfX1+zZseOHYqPj1dKSopq166toUOH6qmnnir3PHNzc+Xv76+cnBxZrdaLPu4Xth+76G0AVeHp62s7egrAFa8yM6c6M90ZkNe4UpDXl7ZNmzapU6dOys/P11VXXSVJ+uWXX+Tq6qqkpCR5eXmZZyX7+fmVugTmxx9/bF7usmHDhub9z5w5I09PT1199dWSpHXr1pnbR+UjryuOvMaVgry+tJHXl4fyZk6FvjuwY8cO85rju3btshmr7B846dmzp3r27Gl33GKxaNKkSZo0aZLdmsDAwL/91L5ly5b6+uuvKzxPAAAuRdWZ6QCA8omMjNTq1as1ZswYbd68Wd7e3oqOjtZzzz2nyMhIrV271qw9ceKENm3aZHP/vLw88+8DBw6UGitZd+7lLOHcyGsAcD7k9ZWlQk30NWvWVPY8AACAA5DpAOCcOnToYPc1ukuXLirvF4or8MVjOCHyGgCcE3l95ajQNdEBAAAAAAAAALgSVOhM9K5du573K2OrV6+u8IQAAED1IdMBAHB+5DUAAI5VoSZ6ybXYShQUFCg1NVW7du1SXFxcZcwLAABUAzIdAADnR14DAOBYFWqiT58+vcz1EyZM0MmTJy9qQgAAoPqQ6QAAOD/yGgAAx6rUa6I/+OCDeuONNypzkwAAwAHIdAAAnB95DQBA9ajUJnpycrK8vLwqc5MAAMAByHQAAJwfeQ0AQPWo0OVcevfubXPbMAz9+uuv2rJli8aOHVspEwMAAFWPTAcAwPmR1wAAOFaFmuj+/v42t11cXNS4cWNNmjRJ3bp1q5SJAQCAqkemAwDg/MhrAAAcq0JN9EWLFlX2PAAAgAOQ6QAAOD/yGgAAx7qoa6Jv3bpVb7/9tt5++21t3769suYEAKhk9957rywWiywWi/r27WuuT09PV79+/RQeHi4vLy81btxYU6ZMUXFxcaltvPbaa2rXrp18fHzk6+ur5s2b27yhO3XqlEaNGqVGjRqpRo0a8vf3V8uWLfXSSy/JMIxqOU5UHJkOAIDzI68BAHCMCp2JnpWVpb59+2rt2rUKCAiQJGVnZ6tr16569913FRQUVJlzBABchEWLFumDDz4otf7o0aO68cYbdfToUfn6+uq6667Trl279NRTT+nIkSOaMWOGWTt06FDNmTNHklSvXj0FBgbqyJEj2rBhg/r37y9Jio+P15IlSyRJzZo1U05Ojnbu3KlRo0bJy8tLQ4cOrfqDxQUj0wEAcH7kNQAAjlWhM9GHDh2qEydOKC0tTcePH9fx48e1a9cu5ebm6oknnqjsOQIAKujAgQN64oknFBUVpauvvtpm7IMPPtDRo0clSRs3blRqaqrmzZsnSZozZ44OHz4sSUpOTtacOXPk4uKijz76SD/99JO2b9+uzMxMTZ8+3dzeN998I0nq3r27du3apR9++EFeXl6SpJ9++qnKjxUVQ6YDAOD8yGsAAByrQk30FStW6JVXXlGTJk3MdU2bNtXcuXO1fPnySpscAKDiCgsLFRsbKxcXFyUkJMjV1dVm/NxLtri4uNj8b1FRkdasWSNJev/99yVJV111ld544w35+/urXr16Gjp0qM1lWm6++WZJZzOiefPmuvbaa3XmzBndfPPN+r//+7+qO1BcFDIdAADnR14DAOBYFbqcS3Fxsdzd3Uutd3d3L/M6ugCA6jdx4kRt2rRJb7/9tiIiIkqN33777Ro9erROnjypyMhIXXPNNUpLSzPHf/nlF0nS3r17JUmHDx/WsWPHdM0112j37t2aM2eO0tPT9dlnn0mS5s+fr+LiYr355pvmdjw8PNSyZUvVrFmzqg8XFUSmAwDg/MhrAAAcq0Jnov/jH//Qk08+qSNHjpjrfvnlFw0fPly33HJLpU0OAFAxW7Zs0eTJk/Xggw8qNja2zJprrrlGK1euVNeuXeXi4qIjR46oX79+slgskmS+USssLDTvs3LlSu3atUsTJ06UJC1btkzp6emSpOnTp+utt95Shw4dlJWVpbS0NPn5+Wnu3Ll6+umnq/BocTHIdAAAnB95DQCAY1WoiT5nzhzl5uaqfv36atCggRo0aKCIiAjl5uZq9uzZlT1HAMAF2rVrl4qKivThhx/K19dXvr6+OnTokCTpf//7n3x9fZWTk6OoqCitXr1a2dnZysrK0oABA8xLtDRu3FjS2cu4lGjXrp0k6cYbbzTXpaen6/Tp0xo7dqwMw1CfPn0UFBSkpk2bqkOHDpKkr776qlqOGxeOTAcAwPmR1wAAOFaFLucSFhambdu26auvvtL3338vSWrSpImio6MrdXIAgItz5syZUusKCwtVWFgowzD0zTffKCoqSq6urvr999/173//W5JUu3Zt86ym6OhoLV68WNLZM9w7dOigLVu2SJIsFosaNmyo06dPm2esb9261dx3yWVdfHx8qvQ4UXFkOgAAzo+8BgDAsS7oTPTVq1eradOmys3NlcVi0a233qqhQ4dq6NChateunZo1a6avv/66quYKACinfv36yTAMmyU8PFySdN9998kwDAUEBOixxx5T7dq11bJlS1199dX69ttv5erqqvnz56tGjRqSpHvvvVdt27aVJHXr1k0tWrTQ2LFjJUn9+/fX1Vdfrdq1a6tTp06SpISEBDVq1Ej169fXgQMHJElxcXHV/RDgb5DpAAA4P/IaAADncEFN9BkzZmjQoEGyWq2lxvz9/fXoo49q2rRplTY5AEDV6tatm6xWq/bu3Ss3Nzd169ZNq1evVp8+fcwad3d3rVy5Uo8++qisVqv279+vZs2aacaMGVqwYIFZt3TpUo0aNUrXXnutjhw5ovz8fEVGRurtt9/Wv/71L0ccHs6DTAcAwPmR1wAAOAeLUXLx23IIDw/XihUr1KRJkzLHv//+e3Xr1s287u6VJDc3V/7+/srJySnzHzgX6oXtxyphVkDle/r62o6eAnDFq4zMuVIznbzGlYK8BhyPvK448hpXCvIacLzyZs4FnYmemZkpd3d3u+Nubm46evTohWwSAAA4AJkOAIDzI68BAHAOF9REv+qqq7Rr1y674zt27FDdunUvelIAAKBqkekAADg/8hoAAOdwQU3022+/XWPHjtWZM2dKjf3xxx8aP368evbsWWmTA4CKsFhYWJxzcSaOyPRffvlFDz74oGrVqiVvb2+1aNFCW7ZsMccNw9C4ceNUt25deXt7Kzo6Wvv27bPZxvHjxxUbGyur1aqAgAANHDhQJ0+erNR5Aqgejn5NZmGxtzgT3oMDcAaOfl1mYSlrqW4X1EQfM2aMjh8/rmuvvVZTpkzRJ598ok8++UQvvviiGjdurOPHj+s///lPVc0VAABUkurO9N9//10dOnSQu7u7li9frt27d+vll19WzZo1zZopU6Zo1qxZmj9/vjZt2iQfHx/FxMTYNA5iY2OVlpampKQkLVu2TOvXr9fgwYMrbZ4AADgTR7wH50NvAABKc7uQ4uDgYH377bd6/PHHNXr0aJX8JqnFYlFMTIzmzp2r4ODgKpkoAACoPNWd6S+++KLCwsK0aNEic11ERIT5t2EYmjFjhsaMGaM777xTkvTmm28qODhYS5cuVd++fbVnzx6tWLFCKSkpatu2rSRp9uzZuv322zV16lSFhoZW2nwBAHAG1Z3XJR96d+3aVcuXL1dQUJD27dtX5ofeS5YsUUREhMaOHauYmBjt3r1bXl5eks5+6P3rr78qKSlJBQUF6t+/vwYPHqzExMRKmysAANXpgpro0tlfB//iiy/0+++/a//+/TIMQ40aNbIJVQAA4PyqM9M//fRTxcTE6J577tG6det01VVX6V//+pcGDRokSTp48KAyMjIUHR1t3sff31+RkZFKTk5W3759lZycrICAALOBLknR0dFycXHRpk2bdNddd1X6vAEAcLTqzGs+9AYAoGwXdDmXc9WsWVPt2rXTjTfeSAMdAIBLWHVk+o8//qh58+apUaNG+vLLL/X444/riSee0JIlSyRJGRkZklTqbLrg4GBzLCMjQ3Xq1LEZd3NzU2BgoFnzV3l5ecrNzbVZAAC4FFVHXn/66adq27at7rnnHtWpU0fXX3+9Fi5caI7/3Yfekv72Q++ykNcAAGdX4SY6AABAeRUXF+uGG27Q888/r+uvv16DBw/WoEGDNH/+/Crd7+TJk+Xv728uYWFhVbo/AAAuZY760Ju8BgA4O5roAACgytWtW1dNmza1WdekSRMdOnRIkhQSEiJJyszMtKnJzMw0x0JCQpSVlWUzXlhYqOPHj5s1fzV69Gjl5OSYy+HDhyvleAAAuBw56kNv8hoA4OxoogMAgCrXoUMH7d2712bdDz/8oPDwcElnr7caEhKiVatWmeO5ubnatGmToqKiJElRUVHKzs7W1q1bzZrVq1eruLhYkZGRZe7X09NTVqvVZgEAAGVz1Ife5DUAwNnRRAcAAFVu+PDh2rhxo55//nnt379fiYmJWrBggeLj4yVJFotFw4YN03PPPadPP/1UO3fu1MMPP6zQ0FD16tVL0tk38d27d9egQYO0efNmbdiwQUOGDFHfvn35kTIAACqBoz70BgDA2bk5egIAAODy165dO3388ccaPXq0Jk2apIiICM2YMUOxsbFmzahRo3Tq1CkNHjxY2dnZ6tixo1asWCEvLy+zJiEhQUOGDNEtt9wiFxcX9enTR7NmzXLEIQEAcNkZPny42rdvr+eff1733nuvNm/erAULFmjBggWSbD/0btSokSIiIjR27Fi7H3rPnz9fBQUFfOgNALjk0UQHAADVomfPnurZs6fdcYvFokmTJmnSpEl2awIDA5WYmFgV0wMA4IrHh94AAJSNJjoAAAAAAJDEh94AAJSFa6IDAAAAAAAAAGAHTXQAAAAAAAAAAOygiQ4AAAAAAAAAgB000QEAAAAAAAAAsIMmOgAAAAAAAAAAdtBEBwAAAAAAAADADproAAAAAAAAAADYQRMdAAAAAAAAAAA7aKIDAAAAAAAAAGAHTXQAAAAAAAAAAOygiQ4AAAAAAAAAgB000QEAAAAAAAAAsOOSaqK/8MILslgsGjZsmLnuzJkzio+PV61ateTr66s+ffooMzPT5n6HDh1Sjx49VKNGDdWpU0cjR45UYWGhTc3atWt1ww03yNPTUw0bNtTixYur4YgAAAAAAAAAAM7skmmip6Sk6NVXX1XLli1t1g8fPlyfffaZPvjgA61bt05HjhxR7969zfGioiL16NFD+fn5+vbbb7VkyRItXrxY48aNM2sOHjyoHj16qGvXrkpNTdWwYcP0yCOP6Msvv6y24wMAAAAAAAAAOJ9Lool+8uRJxcbGauHChapZs6a5PicnR6+//rqmTZumf/zjH2rTpo0WLVqkb7/9Vhs3bpQkrVy5Urt379bbb7+t1q1b67bbbtOzzz6ruXPnKj8/X5I0f/58RURE6OWXX1aTJk00ZMgQ3X333Zo+fbpDjhcAAAAAAAAA4BwuiSZ6fHy8evTooejoaJv1W7duVUFBgc366667TvXq1VNycrIkKTk5WS1atFBwcLBZExMTo9zcXKWlpZk1f912TEyMuY2y5OXlKTc312YBAAAAAAAAAFxe3Bw9gb/z7rvvatu2bUpJSSk1lpGRIQ8PDwUEBNisDw4OVkZGhllzbgO9ZLxk7Hw1ubm5+uOPP+Tt7V1q35MnT9bEiRMrfFwAAAAAAAAAAOfn1GeiHz58WE8++aQSEhLk5eXl6OnYGD16tHJycszl8OHDjp4SAAAAAAAAAKCSOXUTfevWrcrKytINN9wgNzc3ubm5ad26dZo1a5bc3NwUHBys/Px8ZWdn29wvMzNTISEhkqSQkBBlZmaWGi8ZO1+N1Wot8yx0SfL09JTVarVZAAAAAAAAAACXF6duot9yyy3auXOnUlNTzaVt27aKjY01/3Z3d9eqVavM++zdu1eHDh1SVFSUJCkqKko7d+5UVlaWWZOUlCSr1aqmTZuaNeduo6SmZBsAAAAAAAAAgCuTU18T3c/PT82bN7dZ5+Pjo1q1apnrBw4cqBEjRigwMFBWq1VDhw5VVFSUbrrpJklSt27d1LRpUz300EOaMmWKMjIyNGbMGMXHx8vT01OS9Nhjj2nOnDkaNWqUBgwYoNWrV+v999/X559/Xr0HDAAAAAAAAABwKk7dRC+P6dOny8XFRX369FFeXp5iYmL0yiuvmOOurq5atmyZHn/8cUVFRcnHx0dxcXGaNGmSWRMREaHPP/9cw4cP18yZM3X11VfrtddeU0xMjCMOCQAAAAAAAADgJC65JvratWttbnt5eWnu3LmaO3eu3fuEh4friy++OO92u3Tpou3bt1fGFAEAAAAAAAAAlwmnviY6AAAAAAAAAACORBMdAAAAAAAAAAA7aKIDAAAAAAAAAGAHTXQAAAAAAAAAAOygiQ4AAAAAAAAAgB000QEAAAAAAAAAsIMmOgAAAAAAAAAAdtBEBwAAAAAAAADADproAAAAAAAAAADYQRMdAAAAAAAAAAA7aKIDAAAAAAAAAGAHTXQAAAAAAAAAAOygiQ4AAKrdCy+8IIvFomHDhpnrzpw5o/j4eNWqVUu+vr7q06ePMjMzbe536NAh9ejRQzVq1FCdOnU0cuRIFRYWVvPsAQC4MpDXAACcRRMdAABUq5SUFL366qtq2bKlzfrhw4frs88+0wcffKB169bpyJEj6t27tzleVFSkHj16KD8/X99++62WLFmixYsXa9y4cdV9CAAAXPbIawAA/kQTHQAAVJuTJ08qNjZWCxcuVM2aNc31OTk5ev311zVt2jT94x//UJs2bbRo0SJ9++232rhxoyRp5cqV2r17t95++221bt1at912m5599lnNnTtX+fn5jjokAAAuO+Q1AAC2aKIDAIBqEx8frx49eig6Otpm/datW1VQUGCz/rrrrlO9evWUnJwsSUpOTlaLFi0UHBxs1sTExCg3N1dpaWll7i8vL0+5ubk2CwAAOD/yGgAAW26OngAAALgyvPvuu9q2bZtSUlJKjWVkZMjDw0MBAQE264ODg5WRkWHWnPuGvGS8ZKwskydP1sSJEyth9gAAXBnIawAASuNMdAAAUOUOHz6sJ598UgkJCfLy8qq2/Y4ePVo5OTnmcvjw4WrbNwAAlxryGgCAstFEBwAAVW7r1q3KysrSDTfcIDc3N7m5uWndunWaNWuW3NzcFBwcrPz8fGVnZ9vcLzMzUyEhIZKkkJAQZWZmlhovGSuLp6enrFarzQIAAMpGXgMAUDaa6AAAoMrdcsst2rlzp1JTU82lbdu2io2NNf92d3fXqlWrzPvs3btXhw4dUlRUlCQpKipKO3fuVFZWllmTlJQkq9Wqpk2bVvsxAQBwuSGvAQAoG9dEBwAAVc7Pz0/Nmze3Wefj46NatWqZ6wcOHKgRI0YoMDBQVqtVQ4cOVVRUlG666SZJUrdu3dS0aVM99NBDmjJlijIyMjRmzBjFx8fL09Oz2o8JAIDLDXkNAEDZaKIDAACnMH36dLm4uKhPnz7Ky8tTTEyMXnnlFXPc1dVVy5Yt0+OPP66oqCj5+PgoLi5OkyZNcuCsAQC4spDXAIArkcUwDMPRk7gc5Obmyt/fXzk5OZVy/bYXth+rhFkBle/p62s7egp/y2Jx9AyAslVW4lZ25lxJyGtcKchroOLIa8cjr3GluBTyWiKz4ZyqO6+5JjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALDDqZvokydPVrt27eTn56c6deqoV69e2rt3r03NmTNnFB8fr1q1asnX11d9+vRRZmamTc2hQ4fUo0cP1ahRQ3Xq1NHIkSNVWFhoU7N27VrdcMMN8vT0VMOGDbV48eKqPjwAAAAAAAAAgJNz6ib6unXrFB8fr40bNyopKUkFBQXq1q2bTp06ZdYMHz5cn332mT744AOtW7dOR44cUe/evc3xoqIi9ejRQ/n5+fr222+1ZMkSLV68WOPGjTNrDh48qB49eqhr165KTU3VsGHD9Mgjj+jLL7+s1uMFAAAAAAAAADgXN0dP4HxWrFhhc3vx4sWqU6eOtm7dqk6dOiknJ0evv/66EhMT9Y9//EOStGjRIjVp0kQbN27UTTfdpJUrV2r37t366quvFBwcrNatW+vZZ5/VU089pQkTJsjDw0Pz589XRESEXn75ZUlSkyZN9M0332j69OmKiYmp9uMGAAAAAAAAADgHpz4T/a9ycnIkSYGBgZKkrVu3qqCgQNHR0WbNddddp3r16ik5OVmSlJycrBYtWig4ONisiYmJUW5urtLS0syac7dRUlOyjbLk5eUpNzfXZgEAAAAAAAAAXF4umSZ6cXGxhg0bpg4dOqh58+aSpIyMDHl4eCggIMCmNjg4WBkZGWbNuQ30kvGSsfPV5Obm6o8//ihzPpMnT5a/v7+5hIWFXfQxAgAAAAAAAACcyyXTRI+Pj9euXbv07rvvOnoqkqTRo0crJyfHXA4fPuzoKQEAAAAAAAAAKplTXxO9xJAhQ7Rs2TKtX79eV199tbk+JCRE+fn5ys7OtjkbPTMzUyEhIWbN5s2bbbaXmZlpjpX8b8m6c2usVqu8vb3LnJOnp6c8PT0v+tgAAAAAAAAAAM7Lqc9ENwxDQ4YM0ccff6zVq1crIiLCZrxNmzZyd3fXqlWrzHV79+7VoUOHFBUVJUmKiorSzp07lZWVZdYkJSXJarWqadOmZs252yipKdkGAAAAAAAAAODK5NRnosfHxysxMVGffPKJ/Pz8zGuY+/v7y9vbW/7+/ho4cKBGjBihwMBAWa1WDR06VFFRUbrpppskSd26dVPTpk310EMPacqUKcrIyNCYMWMUHx9vnkn+2GOPac6cORo1apQGDBig1atX6/3339fnn3/usGMHAAAAAAAAADieU5+JPm/ePOXk5KhLly6qW7euubz33ntmzfTp09WzZ0/16dNHnTp1UkhIiD766CNz3NXVVcuWLZOrq6uioqL04IMP6uGHH9akSZPMmoiICH3++edKSkpSq1at9PLLL+u1115TTExMtR4vAAAAAAAAAMC5OPWZ6IZh/G2Nl5eX5s6dq7lz59qtCQ8P1xdffHHe7XTp0kXbt2+/4DkCAAAAAAAAAC5fTn0mOgAAuDxMnjxZ7dq1k5+fn+rUqaNevXpp7969NjVnzpxRfHy8atWqJV9fX/Xp06fUD38fOnRIPXr0UI0aNVSnTh2NHDlShYWF1XkoAABctshrAADKRhMdAABUuXXr1ik+Pl4bN25UUlKSCgoK1K1bN506dcqsGT58uD777DN98MEHWrdunY4cOaLevXub40VFRerRo4fy8/P17bffasmSJVq8eLHGjRvniEMCAOCyQ14DAFA2i1Gea6bgb+Xm5srf3185OTmyWq0Xvb0Xth+rhFkBle/p62s7egp/y2Jx9AyAslVW4lZ25jjC0aNHVadOHa1bt06dOnVSTk6OgoKClJiYqLvvvluS9P3336tJkyZKTk7WTTfdpOXLl6tnz546cuSIgoODJUnz58/XU089paNHj8rDw+Nv90te40pBXgMVR17/ibwGqtalkNcSmQ3nVN15zZnoAACg2uXk5EiSAgMDJUlbt25VQUGBoqOjzZrrrrtO9erVU3JysiQpOTlZLVq0MN+QS1JMTIxyc3OVlpZWjbMHAODKQF4DAHCWU/+wKAAAuPwUFxdr2LBh6tChg5o3by5JysjIkIeHhwICAmxqg4ODlZGRYdac+4a8ZLxkrCx5eXnKy8szb+fm5lbWYQAAcFkjrwEA+BNnogMAgGoVHx+vXbt26d13363yfU2ePFn+/v7mEhYWVuX7BADgckBeAwDwJ5roAACg2gwZMkTLli3TmjVrdPXVV5vrQ0JClJ+fr+zsbJv6zMxMhYSEmDWZmZmlxkvGyjJ69Gjl5OSYy+HDhyvxaAAAuDyR1wAA2KKJDgAAqpxhGBoyZIg+/vhjrV69WhERETbjbdq0kbu7u1atWmWu27t3rw4dOqSoqChJUlRUlHbu3KmsrCyzJikpSVarVU2bNi1zv56enrJarTYLAAAoG3kNAEDZuCY6AACocvHx8UpMTNQnn3wiPz8/85qo/v7+8vb2lr+/vwYOHKgRI0YoMDBQVqtVQ4cOVVRUlG666SZJUrdu3dS0aVM99NBDmjJlijIyMjRmzBjFx8fL09PTkYcHAMBlgbwGAKBsNNEBAECVmzdvniSpS5cuNusXLVqkfv36SZKmT58uFxcX9enTR3l5eYqJidErr7xi1rq6umrZsmV6/PHHFRUVJR8fH8XFxWnSpEnVdRgAAFzWyGsAAMpGEx0AAFQ5wzD+tsbLy0tz587V3Llz7daEh4friy++qMypAQCA/4+8BgCgbFwTHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNEBAAAAAAAAALCDJjoAAAAAAAAAAHbQRAcAAAAAAAAAwA6a6AAAAAAAAAAA2EETHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoIkOAAAAAAAAAIAdNNH/Yu7cuapfv768vLwUGRmpzZs3O3pKAADgL8hrAACcH3kNALhc0EQ/x3vvvacRI0Zo/Pjx2rZtm1q1aqWYmBhlZWU5emoAAOD/I68BAHB+5DUA4HJCE/0c06ZN06BBg9S/f381bdpU8+fPV40aNfTGG284emoAAOD/I68BAHB+5DUA4HLi5ugJOIv8/Hxt3bpVo0ePNte5uLgoOjpaycnJperz8vKUl5dn3s7JyZEk5ebmVsp8zpw8USnbASpbbq6Ho6cAXLIqKSLMrDEMo3I2eAkhr4HyIa+BiiOvLx55DZQPeQ1UXHXnNU30/+/YsWMqKipScHCwzfrg4GB9//33peonT56siRMnllofFhZWZXMEnEHp/+oBlJe/f+Vu78SJE/Kv7I06OfIaKB/yGqg48vrikddA+ZDXQMVVd17TRK+g0aNHa8SIEebt4uJiHT9+XLVq1ZLFYnHgzHCu3NxchYWF6fDhw7JarY6eDnDJ4TnknAzD0IkTJxQaGuroqTg98vrSwGsNcHF4Djkn8rr8yOtLA681wMXhOeScypvXNNH/v9q1a8vV1VWZmZk26zMzMxUSElKq3tPTU56enjbrAgICqnKKuAhWq5UXKOAi8BxyPlfaGW0lyOvLG681wMXhOeR8yGvy+nLEaw1wcXgOOZ/y5DU/LPr/eXh4qE2bNlq1apW5rri4WKtWrVJUVJQDZwYAAEqQ1wAAOD/yGgBwueFM9HOMGDFCcXFxatu2rW688UbNmDFDp06dUv/+/R09NQAA8P+R1wAAOD/yGgBwOaGJfo777rtPR48e1bhx45SRkaHWrVtrxYoVpX4MBZcOT09PjR8/vtRXAwGUD88hOCPy+vLDaw1wcXgOwRmR15cfXmuAi8Nz6NJmMQzDcPQkAAAAAAAAAABwRlwTHQAAAAAAAAAAO2iiAwAAAAAAAABgB010AAAAAAAAAADsoImOK0r9+vU1Y8YMR08DcIj09HRZLBalpqZKktauXSuLxaLs7GyHzgsAykJm40pFXgO4lJDXuFKR11cemuhwCv369ZPFYjGXWrVqqXv37tqxY0el7iclJUWDBw+u1G0CVankufHYY4+VGouPj5fFYlG/fv0qtO327dvr119/lb+//0XOsvItXrxYAQEBjp4GgDKQ2UBp5DUAZ0NeA6WR17gYNNHhNLp3765ff/1Vv/76q1atWiU3Nzf17NmzUvcRFBSkGjVqVOo2gaoWFhamd999V3/88Ye57syZM0pMTFS9evUqvF0PDw+FhITIYrFUxjQBXEHIbKA08hqAsyGvgdLIa1QUTXQ4DU9PT4WEhCgkJEStW7fW008/rcOHD+vo0aOSpMOHD+vee+9VQECAAgMDdeeddyo9Pd28f79+/dSrVy9NnTpVdevWVa1atRQfH6+CggKz5q9fNfv+++/VsWNHeXl5qWnTpvrqq69ksVi0dOlSSX9+Peejjz5S165dVaNGDbVq1UrJycnV8ZAAkqQbbrhBYWFh+uijj8x1H330kerVq6frr7/eXLdixQp17NhRAQEBqlWrlnr27KkDBw7Y3W5ZXzdbuHChwsLCVKNGDd11112aNm2azSfWEyZMUOvWrfXWW2+pfv368vf3V9++fXXixIlyz+Pvnldr165V//79lZOTY545M2HChIt4BAFUNjIbKI28Jq8BZ0NeA6WR1+R1RdFEh1M6efKk3n77bTVs2FC1atVSQUGBYmJi5Ofnp6+//lobNmyQr6+vunfvrvz8fPN+a9as0YEDB7RmzRotWbJEixcv1uLFi8vcR1FRkXr16qUaNWpo06ZNWrBggf7zn/+UWfuf//xH//73v5Wamqprr71W999/vwoLC6vi0IEyDRgwQIsWLTJvv/HGG+rfv79NzalTpzRixAht2bJFq1atkouLi+666y4VFxeXax8bNmzQY489pieffFKpqam69dZb9d///rdU3YEDB7R06VItW7ZMy5Yt07p16/TCCy9c8DzsPa/at2+vGTNmyGq1mmfO/Pvf/76QhwtANSKzgT+R1+Q14KzIa+BP5DV5XSEG4ATi4uIMV1dXw8fHx/Dx8TEkGXXr1jW2bt1qGIZhvPXWW0bjxo2N4uJi8z55eXmGt7e38eWXX5rbCA8PNwoLC82ae+65x7jvvvvM2+Hh4cb06dMNwzCM5cuXG25ubsavv/5qjiclJRmSjI8//tgwDMM4ePCgIcl47bXXzJq0tDRDkrFnz55KfxyAv4qLizPuvPNOIysry/D09DTS09ON9PR0w8vLyzh69Khx5513GnFxcWXe9+jRo4YkY+fOnYZh/Pnf8/bt2w3DMIw1a9YYkozff//dMAzDuO+++4wePXrYbCM2Ntbw9/c3b48fP96oUaOGkZuba64bOXKkERkZafcY7M3jfM+rRYsW2ewXgPMgs4HSyGsAzoa8Bkojr3ExOBMdTqNr165KTU1VamqqNm/erJiYGN1222366aef9N1332n//v3y8/OTr6+vfH19FRgYqDNnzth8jaVZs2ZydXU1b9etW1dZWVll7m/v3r0KCwtTSEiIue7GG28ss7Zly5Y225Rkd7tAVQgKClKPHj20ePFiLVq0SD169FDt2rVtavbt26f7779f11xzjaxWq+rXry9JOnToULn2sXfv3lLPgbKeE/Xr15efn595+6/Ps/LOg+cVcOkis4GykdcAnAl5DZSNvEZFuDl6AkAJHx8fNWzY0Lz92muvyd/fXwsXLtTJkyfVpk0bJSQklLpfUFCQ+be7u7vNmMViKfdXbc7n3O2W/EhEZWwXuBADBgzQkCFDJElz584tNX7HHXcoPDxcCxcuVGhoqIqLi9W8eXObr2NWhr97npV3HjyvgEsXmQ3YR14DcBbkNWAfeY0LRRMdTstiscjFxUV//PGHbrjhBr333nuqU6eOrFZrpWy/cePGOnz4sDIzMxUcHCxJSklJqZRtA1Wh5PqEFotFMTExNmO//fab9u7dq4ULF+rmm2+WJH3zzTcXtP3GjRuXeg5c6HOiMuYhnf1l86Kiogu+HwDHILOBP5HXAJwVeQ38ibzGheJyLnAaeXl5ysjIUEZGhvbs2aOhQ4fq5MmTuuOOOxQbG6vatWvrzjvv1Ndff62DBw9q7dq1euKJJ/Tzzz9XaH+33nqrGjRooLi4OO3YsUMbNmzQmDFjJP35qR3gTFxdXbVnzx7t3r3b5iuVklSzZk3VqlVLCxYs0P79+7V69WqNGDHigrY/dOhQffHFF5o2bZr27dunV199VcuXL7+g50NlzEM6+5W2kydPatWqVTp27JhOnz59wdsAUHXIbMA+8hqAsyCvAfvIa1womuhwGitWrFDdunVVt25dRUZGKiUlRR988IG6dOmiGjVqaP369apXr5569+6tJk2aaODAgTpz5kyFPzV3dXXV0qVLdfLkSbVr106PPPKI+cvhXl5elXloQKWxWq1l/jfv4uKid999V1u3blXz5s01fPhwvfTSSxe07Q4dOmj+/PmaNm2aWrVqpRUrVmj48OEX9HyojHlIUvv27fXYY4/pvvvuU1BQkKZMmXLB2wBQdchs4PzIawDOgLwGzo+8xoWwGIZhOHoSgLPYsGGDOnbsqP3796tBgwaOng7gcIMGDdL333+vr7/+2tFTAQAbZDbwJ/IagLMir4E/kdeXNq6Jjivaxx9/LF9fXzVq1Ej79+/Xk08+qQ4dOhDuuGJNnTpVt956q3x8fLR8+XItWbJEr7zyiqOnBQBkNnAO8hqAsyKvgT+R15cXmui4op04cUJPPfWUDh06pNq1ays6Olovv/yyo6cFOMzmzZs1ZcoUnThxQtdcc41mzZqlRx55xNHTAgAyGzgHeQ3AWZHXwJ/I68sLl3MBAAAAAAAAAMAOflgUAAAAAAAAAAA7aKIDAAAAAAAAAGAHTXQAAAAAAAAAAOygiQ4AAAAAAAAAgB000QEAAAAAAAAAsIMmOgAAAAAAAAAAdtBEBwAAAAAAAADADproAAAAAAAAAADYQRMdAAAAAAAAAAA7/h/RY/gYSIfDMAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize distribution\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "for ax, (name, data) in zip(axes, [('Train', train_df), ('Val', val_df), ('Test', test_df)]):\n",
        "    counts = data['label_idx'].value_counts().sort_index()\n",
        "    ax.bar(['Benign', 'Malignant'], counts.values, color=['skyblue', 'blue'])\n",
        "    ax.set_title(f'{name} Set Distribution')\n",
        "    ax.set_ylabel('Count')\n",
        "    for i, v in enumerate(counts.values):\n",
        "        ax.text(i, v + 100, str(v), ha='center', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(PLOTS_DIR, 'data_split_distribution.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPbUBimwzeCU"
      },
      "source": [
        "#####      \n",
        "\n",
        "\n",
        "Note (Why the split is done this way)\n",
        "\n",
        "The dataset is split in two stages to maintain perfect class balance using stratified splitting.\n",
        "First, 10% of the full dataset is reserved as the test set for unbiased final evaluation.\n",
        "Then, 10% of the remaining 90% (i.e., 0.1111) is taken as the validation set, giving an exact 80% train / 10% validation / 10% test split while preserving the benign/malignant distribution in all subsets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CCSHCM4QzlTW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1069b9-0334-4d6f-ddaa-499fe6835578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class weights (for training): {0: 0.7336343115124153, 1: 1.570048309178744}\n"
          ]
        }
      ],
      "source": [
        "# Class Weight Balancing\n",
        "classes = np.unique(y_train)\n",
        "class_weights_array = compute_class_weight('balanced', classes=classes, y=y_train)\n",
        "class_weight = {int(c): float(w) for c, w in zip(classes, class_weights_array)}\n",
        "\n",
        "print(f\"\\nClass weights (for training): {class_weight}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exo-cHl6Ce_n"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj7gChfDChNO"
      },
      "source": [
        "## **Part Two: Model Training and Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "d8hnWIppDKDF"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.callbacks import (\n",
        "    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        ")\n",
        "import math\n",
        "import os\n",
        "import seaborn as sns\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    classification_report, confusion_matrix, roc_curve, auc\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5N0CPqKE9Ms"
      },
      "source": [
        "**Data Generators**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "nKyxJfbVFAhQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee4f7118-5bac-45d9-ef2c-4f1370223e6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15600 validated image filenames.\n",
            "Found 1950 validated image filenames.\n",
            "\n",
            "Steps per epoch: 488\n",
            "Validation steps: 61\n"
          ]
        }
      ],
      "source": [
        "# Training generator with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    brightness_range=[0.8, 1.2]\n",
        ")\n",
        "\n",
        "# Validation generator (no augmentation)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='path',\n",
        "    y_col='label_idx',\n",
        "    target_size=IMG_SIZE,\n",
        "    class_mode='raw',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=RANDOM_STATE\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    x_col='path',\n",
        "    y_col='label_idx',\n",
        "    target_size=IMG_SIZE,\n",
        "    class_mode='raw',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "steps_per_epoch = math.ceil(len(train_df) / BATCH_SIZE)\n",
        "val_steps = math.ceil(len(val_df) / BATCH_SIZE)\n",
        "\n",
        "print(f\"\\nSteps per epoch: {steps_per_epoch}\")\n",
        "print(f\"Validation steps: {val_steps}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYJjSx-Ky7yh"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "b6zSFv2d1KVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac219d4-dbf4-4ead-c8e3-a6d50a7eae6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Best CV model not found at /content/drive/MyDrive/DermAI_models_resnet/best_resnet50_fold2.keras\n",
            "Building new model from scratch...\n"
          ]
        }
      ],
      "source": [
        "# Load Best Cross-Validation Model\n",
        "#  to initialize final fine-tuning.\n",
        "BEST_CV_MODEL_PATH = \"/content/drive/MyDrive/DermAI_models_resnet/best_resnet50_fold2.keras\"\n",
        "if not os.path.exists(BEST_CV_MODEL_PATH):\n",
        "    print(f\"Warning: Best CV model not found at {BEST_CV_MODEL_PATH}\")\n",
        "    print(\"Building new model from scratch...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsmmzHpuy93r"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMDmGUZ8Fy7q"
      },
      "source": [
        "**Model Building**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "LkR6aL9QFxkH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe265fb-7b4b-44a5-ac17-a6a7e42799b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEST_CV_MODEL_PATH not found, building model from scratch.\n",
            "\n",
            "Model compiled successfully\n",
            "Total parameters: 24,637,313\n",
            "Trainable parameters: 16,881,409\n"
          ]
        }
      ],
      "source": [
        "# Load Best Cross-Validation Model path\n",
        "BEST_CV_MODEL_PATH = \"/content/drive/MyDrive/DermAI_models_resnet/best_resnet50_fold2.keras\"\n",
        "\n",
        "# Build ResNet50 binary classifier with fine-tuning of the last N layers\n",
        "\n",
        "if os.path.exists(BEST_CV_MODEL_PATH):\n",
        "    print(f\"Loading model from: {BEST_CV_MODEL_PATH}\")\n",
        "    model = load_model(BEST_CV_MODEL_PATH)\n",
        "else:\n",
        "    print(\"BEST_CV_MODEL_PATH not found, building model from scratch.\")\n",
        "    def build_resnet_binary(input_shape=(224,224,3), unfreeze_last_n=40):\n",
        "        base = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "        for layer in base.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "        for layer in base.layers[-unfreeze_last_n:]:\n",
        "            if 'batch_normalization' not in layer.name:\n",
        "                layer.trainable = True\n",
        "\n",
        "        x = GlobalAveragePooling2D()(base.output)\n",
        "        x = Dropout(0.4)(x)\n",
        "        x = Dense(512, activation='relu')(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        outputs = Dense(1, activation='sigmoid', dtype='float32')(x)\n",
        "\n",
        "        model = Model(inputs=base.input, outputs=outputs)\n",
        "        return model\n",
        "\n",
        "    model = build_resnet_binary(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), unfreeze_last_n=40)\n",
        "\n",
        "# Recompile with final training settings\n",
        "model.compile(\n",
        "    optimizer=AdamW(learning_rate=1e-5, weight_decay=1e-4),\n",
        "    loss=tf.keras.losses.BinaryFocalCrossentropy(\n",
        "    alpha=0.25,\n",
        "    gamma=2.0\n",
        "    ),\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall'),\n",
        "        tf.keras.metrics.AUC(name='auc')\n",
        "    ]\n",
        ")\n",
        "print(\"\\nModel compiled successfully\")\n",
        "print(f\"Total parameters: {model.count_params():,}\")\n",
        "trainable_params = sum([tf.size(w).numpy() for w in model.trainable_weights])\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "iGXvXEwp6v8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a79996e-d05a-40f1-ae55-edf9dfdc715e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Callbacks configured:\n",
            "  Early stopping: patience=8, monitor=val_recall\n",
            "  Model checkpoint: /content/drive/MyDrive/DermAI_FinalTraining_Model/final_model_best.keras\n",
            "  Learning rate reduction: factor=0.5, patience=3\n",
            "  Training log: /content/drive/MyDrive/DermAI_FinalTraining_Model/training_log.csv\n"
          ]
        }
      ],
      "source": [
        "# Setup Callbacks\n",
        "best_model_path = os.path.join(MODEL_SAVE_DIR, \"final_model_best.keras\")\n",
        "final_model_path = os.path.join(MODEL_SAVE_DIR, \"final_model_complete.keras\")\n",
        "csv_log_path = os.path.join(MODEL_SAVE_DIR, \"training_log.csv\")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=8,\n",
        "        restore_best_weights=True,\n",
        "        mode='min',\n",
        "        verbose=1\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        best_model_path,\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        mode='min',\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    ),\n",
        "    CSVLogger(csv_log_path, append=False)\n",
        "]\n",
        "\n",
        "print(f\"\\nCallbacks configured:\")\n",
        "print(f\"  Early stopping: patience=8, monitor=val_recall\")\n",
        "print(f\"  Model checkpoint: {best_model_path}\")\n",
        "print(f\"  Learning rate reduction: factor=0.5, patience=3\")\n",
        "print(f\"  Training log: {csv_log_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgzHe6mtGMfF"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoGfmc1v68a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc0e2e3-61e5-4966-c813-feef2648e3a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started at: 2025-12-13 17:58:59\n",
            "Epoch 1/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16s/step - accuracy: 0.7059 - auc: 0.7715 - loss: 0.1511 - precision: 0.5350 - recall: 0.6968 \n",
            "Epoch 1: val_loss improved from inf to 0.11480, saving model to /content/drive/MyDrive/DermAI_FinalTraining_Model/final_model_best.keras\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9039s\u001b[0m 19s/step - accuracy: 0.7060 - auc: 0.7716 - loss: 0.1510 - precision: 0.5350 - recall: 0.6969 - val_accuracy: 0.7892 - val_auc: 0.8730 - val_loss: 0.1148 - val_precision: 0.8035 - val_recall: 0.4477 - learning_rate: 1.0000e-05\n",
            "Epoch 2/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step - accuracy: 0.7758 - auc: 0.8639 - loss: 0.1177 - precision: 0.6172 - recall: 0.7736\n",
            "Epoch 2: val_loss did not improve from 0.11480\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 566ms/step - accuracy: 0.7758 - auc: 0.8639 - loss: 0.1177 - precision: 0.6172 - recall: 0.7736 - val_accuracy: 0.7697 - val_auc: 0.8682 - val_loss: 0.1637 - val_precision: 0.8282 - val_recall: 0.3494 - learning_rate: 1.0000e-05\n",
            "Epoch 3/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.7841 - auc: 0.8758 - loss: 0.1131 - precision: 0.6261 - recall: 0.7998\n",
            "Epoch 3: val_loss did not improve from 0.11480\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 555ms/step - accuracy: 0.7841 - auc: 0.8758 - loss: 0.1131 - precision: 0.6261 - recall: 0.7998 - val_accuracy: 0.6118 - val_auc: 0.8926 - val_loss: 0.2276 - val_precision: 0.4499 - val_recall: 0.9839 - learning_rate: 1.0000e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - accuracy: 0.7821 - auc: 0.8752 - loss: 0.1134 - precision: 0.6255 - recall: 0.8068\n",
            "Epoch 4: val_loss did not improve from 0.11480\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 561ms/step - accuracy: 0.7821 - auc: 0.8752 - loss: 0.1134 - precision: 0.6255 - recall: 0.8068 - val_accuracy: 0.7682 - val_auc: 0.8913 - val_loss: 0.1205 - val_precision: 0.5917 - val_recall: 0.8776 - learning_rate: 1.0000e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545ms/step - accuracy: 0.7845 - auc: 0.8809 - loss: 0.1119 - precision: 0.6299 - recall: 0.8021\n",
            "Epoch 5: val_loss did not improve from 0.11480\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 562ms/step - accuracy: 0.7845 - auc: 0.8809 - loss: 0.1119 - precision: 0.6299 - recall: 0.8021 - val_accuracy: 0.6779 - val_auc: 0.8940 - val_loss: 0.1397 - val_precision: 0.4971 - val_recall: 0.9597 - learning_rate: 5.0000e-06\n",
            "Epoch 6/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - accuracy: 0.7867 - auc: 0.8854 - loss: 0.1089 - precision: 0.6281 - recall: 0.8240\n",
            "Epoch 6: val_loss improved from 0.11480 to 0.11408, saving model to /content/drive/MyDrive/DermAI_FinalTraining_Model/final_model_best.keras\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 564ms/step - accuracy: 0.7867 - auc: 0.8854 - loss: 0.1089 - precision: 0.6281 - recall: 0.8240 - val_accuracy: 0.8036 - val_auc: 0.8957 - val_loss: 0.1141 - val_precision: 0.8696 - val_recall: 0.4509 - learning_rate: 5.0000e-06\n",
            "Epoch 7/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - accuracy: 0.7958 - auc: 0.8917 - loss: 0.1049 - precision: 0.6413 - recall: 0.8197\n",
            "Epoch 7: val_loss improved from 0.11408 to 0.09767, saving model to /content/drive/MyDrive/DermAI_FinalTraining_Model/final_model_best.keras\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 564ms/step - accuracy: 0.7958 - auc: 0.8917 - loss: 0.1049 - precision: 0.6413 - recall: 0.8197 - val_accuracy: 0.8272 - val_auc: 0.8945 - val_loss: 0.0977 - val_precision: 0.8034 - val_recall: 0.6055 - learning_rate: 5.0000e-06\n",
            "Epoch 8/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548ms/step - accuracy: 0.7931 - auc: 0.8907 - loss: 0.1061 - precision: 0.6339 - recall: 0.8323\n",
            "Epoch 8: val_loss did not improve from 0.09767\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 565ms/step - accuracy: 0.7931 - auc: 0.8907 - loss: 0.1061 - precision: 0.6339 - recall: 0.8323 - val_accuracy: 0.7262 - val_auc: 0.8825 - val_loss: 0.2639 - val_precision: 0.9677 - val_recall: 0.1449 - learning_rate: 5.0000e-06\n",
            "Epoch 9/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542ms/step - accuracy: 0.7937 - auc: 0.8901 - loss: 0.1053 - precision: 0.6283 - recall: 0.8169\n",
            "Epoch 9: val_loss did not improve from 0.09767\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 558ms/step - accuracy: 0.7937 - auc: 0.8901 - loss: 0.1053 - precision: 0.6283 - recall: 0.8169 - val_accuracy: 0.6631 - val_auc: 0.8959 - val_loss: 0.1685 - val_precision: 0.4855 - val_recall: 0.9678 - learning_rate: 5.0000e-06\n",
            "Epoch 10/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - accuracy: 0.7962 - auc: 0.8927 - loss: 0.1057 - precision: 0.6401 - recall: 0.8302\n",
            "Epoch 10: val_loss did not improve from 0.09767\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 553ms/step - accuracy: 0.7962 - auc: 0.8927 - loss: 0.1057 - precision: 0.6401 - recall: 0.8302 - val_accuracy: 0.7236 - val_auc: 0.9011 - val_loss: 0.1222 - val_precision: 0.5375 - val_recall: 0.9452 - learning_rate: 5.0000e-06\n",
            "Epoch 11/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - accuracy: 0.7855 - auc: 0.8905 - loss: 0.1058 - precision: 0.6255 - recall: 0.8232\n",
            "Epoch 11: val_loss did not improve from 0.09767\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 555ms/step - accuracy: 0.7855 - auc: 0.8905 - loss: 0.1058 - precision: 0.6256 - recall: 0.8232 - val_accuracy: 0.7595 - val_auc: 0.9025 - val_loss: 0.1124 - val_precision: 0.5765 - val_recall: 0.9227 - learning_rate: 2.5000e-06\n",
            "Epoch 12/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.7986 - auc: 0.8948 - loss: 0.1041 - precision: 0.6441 - recall: 0.8245\n",
            "Epoch 12: val_loss did not improve from 0.09767\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 555ms/step - accuracy: 0.7986 - auc: 0.8948 - loss: 0.1041 - precision: 0.6441 - recall: 0.8245 - val_accuracy: 0.8128 - val_auc: 0.8995 - val_loss: 0.0994 - val_precision: 0.6910 - val_recall: 0.7456 - learning_rate: 2.5000e-06\n",
            "Epoch 13/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - accuracy: 0.8021 - auc: 0.8978 - loss: 0.1034 - precision: 0.6554 - recall: 0.8170\n",
            "Epoch 13: val_loss did not improve from 0.09767\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 552ms/step - accuracy: 0.8021 - auc: 0.8978 - loss: 0.1034 - precision: 0.6554 - recall: 0.8170 - val_accuracy: 0.7954 - val_auc: 0.9075 - val_loss: 0.1003 - val_precision: 0.6306 - val_recall: 0.8631 - learning_rate: 2.5000e-06\n",
            "Epoch 14/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.7986 - auc: 0.8986 - loss: 0.1013 - precision: 0.6434 - recall: 0.8321\n",
            "Epoch 14: val_loss did not improve from 0.09767\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 555ms/step - accuracy: 0.7986 - auc: 0.8986 - loss: 0.1013 - precision: 0.6434 - recall: 0.8321 - val_accuracy: 0.7754 - val_auc: 0.9058 - val_loss: 0.1116 - val_precision: 0.5974 - val_recall: 0.9034 - learning_rate: 1.2500e-06\n",
            "Epoch 15/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - accuracy: 0.7968 - auc: 0.8972 - loss: 0.1037 - precision: 0.6466 - recall: 0.8491\n",
            "Epoch 15: val_loss improved from 0.09767 to 0.09265, saving model to /content/drive/MyDrive/DermAI_FinalTraining_Model/final_model_best.keras\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 557ms/step - accuracy: 0.7968 - auc: 0.8972 - loss: 0.1037 - precision: 0.6466 - recall: 0.8491 - val_accuracy: 0.8221 - val_auc: 0.9088 - val_loss: 0.0927 - val_precision: 0.7057 - val_recall: 0.7568 - learning_rate: 1.2500e-06\n",
            "Epoch 16/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547ms/step - accuracy: 0.8079 - auc: 0.9046 - loss: 0.0989 - precision: 0.6544 - recall: 0.8293\n",
            "Epoch 16: val_loss did not improve from 0.09265\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 563ms/step - accuracy: 0.8079 - auc: 0.9046 - loss: 0.0989 - precision: 0.6544 - recall: 0.8293 - val_accuracy: 0.7718 - val_auc: 0.9050 - val_loss: 0.1116 - val_precision: 0.5934 - val_recall: 0.9002 - learning_rate: 1.2500e-06\n",
            "Epoch 17/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - accuracy: 0.8004 - auc: 0.9032 - loss: 0.0997 - precision: 0.6487 - recall: 0.8320\n",
            "Epoch 17: val_loss improved from 0.09265 to 0.09112, saving model to /content/drive/MyDrive/DermAI_FinalTraining_Model/final_model_best.keras\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 556ms/step - accuracy: 0.8004 - auc: 0.9032 - loss: 0.0997 - precision: 0.6487 - recall: 0.8320 - val_accuracy: 0.8318 - val_auc: 0.9094 - val_loss: 0.0911 - val_precision: 0.7322 - val_recall: 0.7440 - learning_rate: 1.2500e-06\n",
            "Epoch 18/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - accuracy: 0.7966 - auc: 0.8973 - loss: 0.1025 - precision: 0.6391 - recall: 0.8194\n",
            "Epoch 18: val_loss did not improve from 0.09112\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 560ms/step - accuracy: 0.7966 - auc: 0.8973 - loss: 0.1025 - precision: 0.6391 - recall: 0.8195 - val_accuracy: 0.8282 - val_auc: 0.9002 - val_loss: 0.0965 - val_precision: 0.8265 - val_recall: 0.5829 - learning_rate: 1.2500e-06\n",
            "Epoch 19/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.8022 - auc: 0.9010 - loss: 0.1006 - precision: 0.6484 - recall: 0.8310\n",
            "Epoch 19: val_loss did not improve from 0.09112\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 555ms/step - accuracy: 0.8022 - auc: 0.9010 - loss: 0.1006 - precision: 0.6484 - recall: 0.8310 - val_accuracy: 0.8010 - val_auc: 0.9098 - val_loss: 0.1031 - val_precision: 0.6369 - val_recall: 0.8728 - learning_rate: 1.2500e-06\n",
            "Epoch 20/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - accuracy: 0.8054 - auc: 0.9026 - loss: 0.1003 - precision: 0.6558 - recall: 0.8223\n",
            "Epoch 20: val_loss did not improve from 0.09112\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 553ms/step - accuracy: 0.8054 - auc: 0.9026 - loss: 0.1003 - precision: 0.6558 - recall: 0.8224 - val_accuracy: 0.7887 - val_auc: 0.9093 - val_loss: 0.0995 - val_precision: 0.6194 - val_recall: 0.8728 - learning_rate: 1.2500e-06\n",
            "Epoch 21/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - accuracy: 0.8057 - auc: 0.9070 - loss: 0.0984 - precision: 0.6534 - recall: 0.8440\n",
            "Epoch 21: val_loss did not improve from 0.09112\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 552ms/step - accuracy: 0.8057 - auc: 0.9070 - loss: 0.0984 - precision: 0.6534 - recall: 0.8440 - val_accuracy: 0.8267 - val_auc: 0.9093 - val_loss: 0.0916 - val_precision: 0.7096 - val_recall: 0.7713 - learning_rate: 6.2500e-07\n",
            "Epoch 22/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - accuracy: 0.8079 - auc: 0.9071 - loss: 0.0977 - precision: 0.6543 - recall: 0.8336\n",
            "Epoch 22: val_loss did not improve from 0.09112\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 554ms/step - accuracy: 0.8079 - auc: 0.9071 - loss: 0.0977 - precision: 0.6543 - recall: 0.8337 - val_accuracy: 0.8062 - val_auc: 0.9111 - val_loss: 0.0962 - val_precision: 0.6552 - val_recall: 0.8261 - learning_rate: 6.2500e-07\n",
            "Epoch 23/50\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - accuracy: 0.8042 - auc: 0.9028 - loss: 0.1006 - precision: 0.6541 - recall: 0.8306\n",
            "Epoch 23: val_loss improved from 0.09112 to 0.08881, saving model to /content/drive/MyDrive/DermAI_FinalTraining_Model/final_model_best.keras\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 558ms/step - accuracy: 0.8042 - auc: 0.9028 - loss: 0.1006 - precision: 0.6541 - recall: 0.8307 - val_accuracy: 0.8446 - val_auc: 0.9087 - val_loss: 0.0888 - val_precision: 0.8023 - val_recall: 0.6795 - learning_rate: 6.2500e-07\n",
            "Epoch 24/50\n",
            "\u001b[1m152/488\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3:13\u001b[0m 575ms/step - accuracy: 0.8167 - auc: 0.9146 - loss: 0.0919 - precision: 0.6502 - recall: 0.8454"
          ]
        }
      ],
      "source": [
        "# Train Final Model\n",
        "start_time = datetime.now()\n",
        "print(f\"Training started at: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=val_steps,\n",
        "    class_weight=class_weight,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "end_time = datetime.now()\n",
        "training_duration = end_time - start_time\n",
        "\n",
        "print(f\"\\nTraining completed at: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Total training time: {training_duration}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmvDZCws7RMP"
      },
      "outputs": [],
      "source": [
        "# Save final model state\n",
        "model.save(final_model_path)\n",
        "print(f\"\\nFinal model saved to: {final_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiAGg0FDdM15"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywd5rG4X7nVW"
      },
      "source": [
        "##### **Load Best Model and Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAEPATQ47j3r"
      },
      "outputs": [],
      "source": [
        "# evaluation on validation set\n",
        "print(\"Evaluation on Validation set\")\n",
        "best_model = load_model(best_model_path)\n",
        "\n",
        "val_gen_eval = val_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    x_col='path',\n",
        "    y_col='label_idx',\n",
        "    target_size=IMG_SIZE,\n",
        "    class_mode='raw',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "preds_prob = best_model.predict(val_gen_eval, steps=val_steps, verbose=1)\n",
        "preds_prob = preds_prob.ravel()\n",
        "preds = (preds_prob > 0.5).astype(int)\n",
        "true = val_df['label_idx'].values[:len(preds)]\n",
        "\n",
        "acc = accuracy_score(true, preds)\n",
        "prec = precision_score(true, preds, zero_division=0)\n",
        "rec = recall_score(true, preds, zero_division=0)\n",
        "f1 = f1_score(true, preds, zero_division=0)\n",
        "\n",
        "print(f\"\\nValidation Performance (threshold=0.5):\")\n",
        "print(f\"  Accuracy:  {acc:.4f}\")\n",
        "print(f\"  Precision: {prec:.4f}\")\n",
        "print(f\"  Recall:    {rec:.4f}\")\n",
        "print(f\"  F1-Score:  {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true, preds, target_names=['Benign', 'Malignant'], zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6JMBuxq7j0I"
      },
      "outputs": [],
      "source": [
        "# evaluation on test set\n",
        "print(\"Evaluation on Test set\")\n",
        "\n",
        "test_gen_eval = val_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='path',\n",
        "    y_col='label_idx',\n",
        "    target_size=IMG_SIZE,\n",
        "    class_mode='raw',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_steps = math.ceil(len(test_df) / BATCH_SIZE)\n",
        "\n",
        "test_preds_prob = best_model.predict(test_gen_eval, steps=test_steps, verbose=1)\n",
        "test_preds_prob = test_preds_prob.ravel()\n",
        "test_preds = (test_preds_prob > 0.5).astype(int)\n",
        "test_true = test_df['label_idx'].values[:len(test_preds)]\n",
        "\n",
        "test_acc = accuracy_score(test_true, test_preds)\n",
        "test_prec = precision_score(test_true, test_preds, zero_division=0)\n",
        "test_rec = recall_score(test_true, test_preds, zero_division=0)\n",
        "test_f1 = f1_score(test_true, test_preds, zero_division=0)\n",
        "\n",
        "print(f\"\\nTest Performance (threshold=0.5):\")\n",
        "print(f\"  Accuracy:  {test_acc:.4f}\")\n",
        "print(f\"  Precision: {test_prec:.4f}\")\n",
        "print(f\"  Recall:    {test_rec:.4f}\")\n",
        "print(f\"  F1-Score:  {test_f1:.4f}\")\n",
        "\n",
        "print(\"\\nTest Classification Report:\")\n",
        "print(classification_report(test_true, test_preds, target_names=['Benign', 'Malignant'], zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX0iZXyv7iyr"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Threshold Optimization for Final Model"
      ],
      "metadata": {
        "id": "38b7fMRKuJOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"_\"*50)\n",
        "print(\"Threshold Optimization\")\n",
        "print(\"_\"*50)\n",
        "\n",
        "# Define thresholds to test\n",
        "thresholds = [0.35, 0.40, 0.45, 0.50, 0.55]\n",
        "\n",
        "print(\"\\nTesting different thresholds on validation set...\")\n",
        "print(\"_\"*50)\n",
        "\n",
        "# Store results\n",
        "threshold_results = []\n",
        "\n",
        "val_preds_prob = preds_prob\n",
        "val_true = true\n",
        "\n",
        "for thresh in thresholds:\n",
        "    # Apply threshold on validation predictions\n",
        "    val_preds_t = (val_preds_prob > thresh).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc_t = accuracy_score(val_true, val_preds_t)\n",
        "    prec_t = precision_score(val_true, val_preds_t, zero_division=0)\n",
        "    rec_t = recall_score(val_true, val_preds_t, zero_division=0)\n",
        "    f1_t = f1_score(val_true, val_preds_t, zero_division=0)\n",
        "\n",
        "    threshold_results.append({\n",
        "        'threshold': thresh,\n",
        "        'accuracy': acc_t,\n",
        "        'precision': prec_t,\n",
        "        'recall': rec_t,\n",
        "        'f1': f1_t\n",
        "    })\n",
        "\n",
        "    print(f\"\\nThreshold = {thresh:.2f}\")\n",
        "    print(f\"  Accuracy:  {acc_t:.4f}\")\n",
        "    print(f\"  Precision: {prec_t:.4f}\")\n",
        "    print(f\"  Recall:    {rec_t:.4f}\")\n",
        "    print(f\"  F1-Score:  {f1_t:.4f}\")\n",
        "\n",
        "# Find best threshold (based on F1-score)\n",
        "threshold_df = pd.DataFrame(threshold_results)\n",
        "best_idx = threshold_df['f1'].idxmax()\n",
        "best_threshold = threshold_df.loc[best_idx, 'threshold']\n",
        "\n",
        "print(\"\\n\" + \"_\"*50)\n",
        "print(f\"Best Threshold: {best_threshold}\")\n",
        "print(\"_\"*50)\n",
        "print(f\"Validation Metrics at Best Threshold:\")\n",
        "print(f\"  Accuracy:  {threshold_df.loc[best_idx, 'accuracy']:.4f}\")\n",
        "print(f\"  Precision: {threshold_df.loc[best_idx, 'precision']:.4f}\")\n",
        "print(f\"  Recall:    {threshold_df.loc[best_idx, 'recall']:.4f}\")\n",
        "print(f\"  F1-Score:  {threshold_df.loc[best_idx, 'f1']:.4f}\")\n",
        "\n",
        "# Apply best threshold to test set\n",
        "print(\"\\n\" + \"_\"*50)\n",
        "print(\"Evaluation on Test set with optimized Threshold\")\n",
        "print(\"_\"*50)\n",
        "\n",
        "test_preds_optimized = (test_preds_prob > best_threshold).astype(int)\n",
        "\n",
        "test_acc_opt = accuracy_score(test_true, test_preds_optimized)\n",
        "test_prec_opt = precision_score(test_true, test_preds_optimized, zero_division=0)\n",
        "test_rec_opt = recall_score(test_true, test_preds_optimized, zero_division=0)\n",
        "test_f1_opt = f1_score(test_true, test_preds_optimized, zero_division=0)\n",
        "\n",
        "print(f\"\\nTest Performance (threshold={best_threshold}):\")\n",
        "print(f\"  Accuracy:  {test_acc_opt:.4f}\")\n",
        "print(f\"  Precision: {test_prec_opt:.4f}\")\n",
        "print(f\"  Recall:    {test_rec_opt:.4f}\")\n",
        "print(f\"  F1-Score:  {test_f1_opt:.4f}\")\n",
        "\n",
        "print(\"\\nTest Classification Report:\")\n",
        "print(classification_report(test_true, test_preds_optimized,\n",
        "                          target_names=['Benign', 'Malignant'],\n",
        "                          zero_division=0))\n",
        "\n",
        "# Comparison with original threshold\n",
        "print(\"\\n\" + \"_\"*50)\n",
        "print(\"COMPARISON: Original (0.5) vs Optimized\")\n",
        "print(\"_\"*50)\n",
        "\n",
        "improvement_acc = (test_acc_opt - test_acc) * 100\n",
        "improvement_prec = (test_prec_opt - test_prec) * 100\n",
        "improvement_rec = (test_rec_opt - test_rec) * 100\n",
        "improvement_f1 = (test_f1_opt - test_f1) * 100\n",
        "\n",
        "print(f\"\\n{'Metric':<12} {'Original':<12} {'Optimized':<12} {'Change':<12}\")\n",
        "print(\"_\"*50)\n",
        "print(f\"{'Threshold':<12} {'0.50':<12} {f'{best_threshold:.2f}':<12} {'-':<12}\")\n",
        "print(f\"{'Accuracy':<12} {test_acc:.4f}{'':<6} {test_acc_opt:.4f}{'':<6} {improvement_acc:+.2f}%\")\n",
        "print(f\"{'Precision':<12} {test_prec:.4f}{'':<6} {test_prec_opt:.4f}{'':<6} {improvement_prec:+.2f}%\")\n",
        "print(f\"{'Recall':<12} {test_rec:.4f}{'':<6} {test_rec_opt:.4f}{'':<6} {improvement_rec:+.2f}%\")\n",
        "print(f\"{'F1-Score':<12} {test_f1:.4f}{'':<6} {test_f1_opt:.4f}{'':<6} {improvement_f1:+.2f}%\")\n",
        "\n",
        "# Plot threshold comparison\n",
        "print(\"\\n\" + \"_\"*100)\n",
        "print(\"Generating Threshold Comparison Plots\")\n",
        "print(\"_\"*100)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1']\n",
        "titles = ['Accuracy vs Threshold', 'Precision vs Threshold',\n",
        "          'Recall vs Threshold', 'F1-Score vs Threshold']\n",
        "colors = ['#1565C0', '#42A5F5', '#90CAF9', '#1E88E5']\n",
        "\n",
        "for idx, (metric, title, color) in enumerate(zip(metrics_to_plot, titles, colors)):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "\n",
        "    # Plot line\n",
        "    ax.plot(threshold_df['threshold'], threshold_df[metric],\n",
        "           marker='o', linewidth=2.5, markersize=8, color=color)\n",
        "\n",
        "    # Mark best threshold\n",
        "    ax.axvline(x=best_threshold, color='red', linestyle='--',\n",
        "              linewidth=2, label=f'Best ({best_threshold})')\n",
        "\n",
        "    # Mark original threshold\n",
        "    ax.axvline(x=0.5, color='gray', linestyle=':',\n",
        "              linewidth=2, alpha=0.7, label='Original (0.5)')\n",
        "\n",
        "    ax.set_xlabel('Threshold', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel(metric.capitalize(), fontsize=12, fontweight='bold')\n",
        "    ax.set_title(title, fontsize=13, fontweight='bold', color='#0D47A1')\n",
        "    ax.legend(fontsize=10)\n",
        "    ax.grid(True, alpha=0.3, linestyle='--')\n",
        "    ax.set_facecolor('#F8F9FA')\n",
        "\n",
        "plt.tight_layout()\n",
        "save_path = os.path.join(PLOTS_DIR, 'threshold_optimization.png')\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
        "plt.show()\n",
        "print(f\"\\nPlot saved: {save_path}\")"
      ],
      "metadata": {
        "id": "vrDJLuolt0pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save threshold analysis results\n",
        "threshold_df.to_csv(os.path.join(PLOTS_DIR, 'threshold_analysis.csv'), index=False)\n",
        "print(f\"Results saved: {os.path.join(PLOTS_DIR, 'threshold_analysis.csv')}\")\n",
        "\n",
        "print(\"\\n\" + \"_\"*50)\n",
        "print(\"Threshold Optimization complete\")\n",
        "print(\"_\"*50)\n",
        "print(f\"\\nRecommended Threshold: {best_threshold}\")\n",
        "print(f\"Expected Test Accuracy: {test_acc_opt:.4f} ({test_acc_opt*100:.2f}%)\")\n",
        "print(f\"Expected Test Recall:   {test_rec_opt:.4f} ({test_rec_opt*100:.2f}%)\")"
      ],
      "metadata": {
        "id": "e-PBJK3IvAM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cPZDTf_-tzAx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHQ2SW2--JKP"
      },
      "source": [
        "#####  **Generating Plots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWh5Arpl-_6T"
      },
      "outputs": [],
      "source": [
        "# Define base model directory\n",
        "MODEL_SAVE_DIR = \"/content/drive/MyDrive/DermAI_FinalTraining_Model\"\n",
        "\n",
        "# Create plots subfolder inside the model directory\n",
        "plots_dir = os.path.join(MODEL_SAVE_DIR, \"training_results_plots\")\n",
        "os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Plots will be saved to: {plots_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSfYMegmIoDP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "best_model_path = \"/content/drive/MyDrive/DermAI_FinalTraining_Model/final_model_best.keras\"\n",
        "model = load_model(best_model_path)\n",
        "print(\"Model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEqX_j5G__yK"
      },
      "source": [
        "**Training Curves**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYNLpsMP_gOv"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation accuracy/loss curves\n",
        "def plot_training_curves(history, save_dir=plots_dir):\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2.5, color='#000099')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2.5, color='#3366FF')\n",
        "    plt.title('Model Accuracy During Training', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Accuracy', fontsize=12)\n",
        "    plt.legend(fontsize=10)\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss', linewidth=2, color='#000099')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss', linewidth=2, color='#3366FF')\n",
        "    plt.title('Model Loss During Training', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Loss', fontsize=12)\n",
        "    plt.legend(fontsize=10)\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(save_dir, 'training_curves.png')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"Saved: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQYFzLuKAHUj"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2HlIPv1AOwL"
      },
      "outputs": [],
      "source": [
        "# Plot confusion matrix for any dataset\n",
        "\"\"\" Args:\n",
        "        true: true labels\n",
        "        preds: predicted labels\n",
        "        dataset_name: 'Validation' or 'Test' or 'Final' \"\"\"\n",
        "\n",
        "def plot_confusion_matrix(true, preds, dataset_name='Validation', save_dir=plots_dir):\n",
        "    cm = confusion_matrix(true, preds)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Blues',\n",
        "        xticklabels=['Benign', 'Malignant'],\n",
        "        yticklabels=['Benign', 'Malignant'],\n",
        "        cbar_kws={'label': 'Count'},\n",
        "        annot_kws={'size': 20}\n",
        "    )\n",
        "    plt.title(f'Confusion Matrix - {dataset_name} Set', fontsize=18, fontweight='bold')\n",
        "    plt.xlabel('Predicted Label', fontsize=20)\n",
        "    plt.ylabel('True Label', fontsize=14)\n",
        "\n",
        "    # Add percentage annotations\n",
        "    total = cm.sum()\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            percentage = (cm[i, j] / total) * 100\n",
        "            plt.text(j + 0.5, i + 0.7, f'({percentage:.1f}%)',\n",
        "                    ha='center', va='center', fontsize=14, color='gray')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(save_dir, f'confusion_matrix_{dataset_name.lower()}.png')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"Saved: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imChBiKQArDs"
      },
      "source": [
        "**ROC Curve**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWe4SVB9AvLM"
      },
      "outputs": [],
      "source": [
        "# Plot ROC curve for any dataset\n",
        "\"\"\" Args:\n",
        "        true: true labels\n",
        "        prob: predicted probabilities\n",
        "        dataset_name: 'Validation' or 'Test' or 'Final' \"\"\"\n",
        "\n",
        "def plot_roc_curve(true, prob, dataset_name='Validation', save_dir=plots_dir):\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(true, prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='#000099', lw=2.5, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
        "    plt.plot([0, 1], [0, 1], color='#3366FF', lw=2, linestyle='--', alpha=0.7)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=12)\n",
        "    plt.ylabel('True Positive Rate (Recall)', fontsize=12)\n",
        "    plt.title(f'ROC Curve - {dataset_name} Set', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc=\"lower right\", fontsize=10)\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(save_dir, f'roc_curve_{dataset_name.lower()}.png')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"Saved: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Osmgd6tBCbm"
      },
      "source": [
        "**Validation vs Test Comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCXoKrO6BBtU"
      },
      "outputs": [],
      "source": [
        "# Compare validation and test performance side by side\n",
        "\"\"\" Args:\n",
        "        val_metrics: dict with keys ['accuracy', 'precision', 'recall', 'f1']\n",
        "        test_metrics: dict with keys ['accuracy', 'precision', 'recall', 'f1'] \"\"\"\n",
        "\n",
        "def plot_val_vs_test_comparison(val_metrics, test_metrics, save_dir=plots_dir):\n",
        "    metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "    val_values = [val_metrics['accuracy'], val_metrics['precision'],\n",
        "                  val_metrics['recall'], val_metrics['f1']]\n",
        "    test_values = [test_metrics['accuracy'], test_metrics['precision'],\n",
        "                   test_metrics['recall'], test_metrics['f1']]\n",
        "\n",
        "    x = np.arange(len(metrics_names))\n",
        "    width = 0.35\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    bars1 = ax.bar(x - width/2, val_values, width, label='Validation',\n",
        "               color='#000099', edgecolor='#0000CC', linewidth=1.5)\n",
        "    bars2 = ax.bar(x + width/2, test_values, width, label='Test',\n",
        "               color='skyblue', edgecolor='skyblue', linewidth=1.5)\n",
        "\n",
        "    ax.set_ylabel('Score', fontsize=12)\n",
        "    ax.set_title('Validation vs Test Performance Comparison',\n",
        "                 fontsize=14, fontweight='bold')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(metrics_names)\n",
        "    ax.legend(fontsize=10)\n",
        "    ax.set_ylim([0, 1])\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bars in [bars1, bars2]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
        "                   f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(save_dir, 'validation_vs_test_comparison.png')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"Saved: {save_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTTbQZFJBibp"
      },
      "source": [
        "**Combined ROC Curves**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQLWn4wABn9z"
      },
      "outputs": [],
      "source": [
        "# Plot validation and test ROC curves on the same figure\n",
        "def plot_combined_roc_curves(val_true, val_prob, test_true, test_prob, save_dir=plots_dir):\n",
        "    # Calculate ROC for validation\n",
        "    val_fpr, val_tpr, _ = roc_curve(val_true, val_prob)\n",
        "    val_auc = auc(val_fpr, val_tpr)\n",
        "\n",
        "    # Calculate ROC for test\n",
        "    test_fpr, test_tpr, _ = roc_curve(test_true, test_prob)\n",
        "    test_auc = auc(test_fpr, test_tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(val_fpr, val_tpr, color='#1565C0', lw=2.5, label=f'Validation (AUC = {val_auc:.3f})')\n",
        "    plt.plot(test_fpr, test_tpr, color='#42A5F5', lw=2.5, label=f'Test (AUC = {test_auc:.3f})')\n",
        "    plt.plot([0, 1], [0, 1], color='#90CAF9', lw=2, linestyle='--', alpha=0.6)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',\n",
        "             label='Random Classifier')\n",
        "\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=12)\n",
        "    plt.ylabel('True Positive Rate (Recall)', fontsize=12)\n",
        "    plt.title('ROC Curves: Validation vs Test', fontsize=14, fontweight='bold')\n",
        "    plt.legend(loc=\"lower right\", fontsize=10)\n",
        "    plt.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(save_dir, 'roc_curves_combined.png')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"Saved: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78XFyJIq82aU"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reBfDqWsDMU2"
      },
      "source": [
        "**Metrics Summary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac2AQd17B1XZ"
      },
      "outputs": [],
      "source": [
        "# Plot bar chart of all metrics\n",
        "def plot_metrics_summary(metrics_dict, dataset_name='Test', save_dir=plots_dir):\n",
        "    metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "    metrics_values = [\n",
        "        metrics_dict['accuracy'],\n",
        "        metrics_dict['precision'],\n",
        "        metrics_dict['recall'],\n",
        "        metrics_dict['f1']\n",
        "    ]\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    bars = plt.bar(metrics_names, metrics_values, color=['#E3F2FD', '#90CAF9', '#42A5F5', '#1E88E5'])\n",
        "    plt.ylim([0, 1.5])\n",
        "    plt.ylabel('Score', fontsize=12)\n",
        "    plt.title(f'{dataset_name} Set Performance Metrics',\n",
        "              fontsize=14, fontweight='bold')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    for bar, val in zip(bars, metrics_values):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, val + 0.02,\n",
        "                f'{val:.3f}', ha='center', va='bottom',\n",
        "                fontweight='bold', fontsize=11)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(save_dir, f'metrics_summary_{dataset_name.lower()}.png')\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f\"Saved: {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e971f9bd"
      },
      "outputs": [],
      "source": [
        "# Generating plots\n",
        "print(\"\\n\" + \"_\"*60)\n",
        "print(\"Generating plots\")\n",
        "print(\"_\"*60)\n",
        "# 1. Training curves (from history)\n",
        "plot_training_curves(history)\n",
        "\n",
        "# 2. Validation performance\n",
        "print(\"\\nValidation Set Visualizations:\")\n",
        "plot_confusion_matrix(true, preds, dataset_name='Validation')\n",
        "plot_roc_curve(true, preds_prob, dataset_name='Validation')\n",
        "\n",
        "val_metrics = {\n",
        "    'accuracy': acc,\n",
        "    'precision': prec,\n",
        "    'recall': rec,\n",
        "    'f1': f1\n",
        "}\n",
        "plot_metrics_summary(val_metrics, dataset_name='Validation')\n",
        "\n",
        "# 3. Test performance\n",
        "print(\"\\nTest Set Visualizations:\")\n",
        "plot_confusion_matrix(test_true, test_preds, dataset_name='Test')\n",
        "plot_roc_curve(test_true, test_preds_prob, dataset_name='Test')\n",
        "\n",
        "test_metrics = {\n",
        "    'accuracy': test_acc,\n",
        "    'precision': test_prec,\n",
        "    'recall': test_rec,\n",
        "    'f1': test_f1\n",
        "}\n",
        "plot_metrics_summary(test_metrics, dataset_name='Test')\n",
        "\n",
        "# 4. Comparison plots\n",
        "print(\"\\nComparison Visualizations:\")\n",
        "plot_val_vs_test_comparison(val_metrics, test_metrics)\n",
        "plot_combined_roc_curves(true, preds_prob, test_true, test_preds_prob)\n",
        "print(\"_\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epO8C1qSNqN1"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnxMPbhHho8d"
      },
      "source": [
        "## **Part Three: Results Analysis and Discussion**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n1. Training Dynamics & Convergence\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "best_epoch = np.argmin(history.history['val_loss']) + 1\n",
        "total_epochs_trained = len(history.history['loss'])\n",
        "best_val_loss = min(history.history['val_loss'])\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(\"\\nTraining Summary:\")\n",
        "print(f\"  Total epochs trained: {total_epochs_trained}/{EPOCHS}\")\n",
        "print(f\"  Best model at epoch: {best_epoch}\")\n",
        "print(f\"  Best validation loss: {best_val_loss:.4f}\")\n",
        "print(f\"  Final training accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"  Final validation accuracy: {final_val_acc:.4f}\")\n",
        "print(f\"  Total training time: {training_duration}\")\n",
        "\n",
        "train_val_gap = final_train_acc - final_val_acc\n",
        "print(\"\\nGeneralization Analysis:\")\n",
        "print(f\"  TrainValidation accuracy gap: {train_val_gap:.4f} ({train_val_gap*100:.2f}%)\")\n",
        "\n",
        "if train_val_gap < 0.05:\n",
        "    print(\"  Interpretation: Excellent generalization with minimal overfitting\")\n",
        "elif train_val_gap < 0.10:\n",
        "    print(\"  Interpretation: Mild overfitting observed\")\n",
        "else:\n",
        "    print(\"  Interpretation: Noticeable overfitting detected\")\n",
        "\n",
        "\n",
        "print(\"\\n\\n2. Baseline Model Performance (Threshold = 0.5)\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "val_auc = auc(*roc_curve(true, preds_prob)[:2])\n",
        "test_auc = auc(*roc_curve(test_true, test_preds_prob)[:2])\n",
        "\n",
        "metrics_table = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC'],\n",
        "    'Validation': [acc, prec, rec, f1, val_auc],\n",
        "    'Test': [test_acc, test_prec, test_rec, test_f1, test_auc],\n",
        "    'Difference': [\n",
        "        test_acc - acc,\n",
        "        test_prec - prec,\n",
        "        test_rec - rec,\n",
        "        test_f1 - f1,\n",
        "        test_auc - val_auc\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nPerformance Metrics Comparison:\")\n",
        "print(metrics_table.round(4).to_string(index=False))\n",
        "\n",
        "print(\"\\nKey Observations:\")\n",
        "print(f\"  Test accuracy {'exceeds' if test_acc > acc else 'is below'} validation accuracy\")\n",
        "print(f\"  PrecisionRecall difference: {abs(test_prec - test_rec):.4f}\")\n",
        "print(f\"  Overall generalization: {'Strong' if test_acc >= 0.80 else 'Acceptable'}\")\n",
        "\n",
        "\n",
        "print(\"\\n\\n3. Threshold Optimization Analysis\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "print(\"\\nMethodology:\")\n",
        "print(\"  Threshold optimization was conducted exclusively on the validation set.\")\n",
        "print(\"  The test set was kept completely unseen to preserve unbiased evaluation.\")\n",
        "\n",
        "print(f\"\\nThresholds evaluated: {thresholds}\")\n",
        "print(f\"Selected optimal threshold: {best_threshold} (based on validation F1-score)\")\n",
        "\n",
        "print(\"\\nValidation Performance at Optimal Threshold:\")\n",
        "print(f\"  Accuracy:  {threshold_df.loc[best_idx, 'accuracy']:.4f}\")\n",
        "print(f\"  Precision: {threshold_df.loc[best_idx, 'precision']:.4f}\")\n",
        "print(f\"  Recall:    {threshold_df.loc[best_idx, 'recall']:.4f}\")\n",
        "print(f\"  F1-Score:  {threshold_df.loc[best_idx, 'f1']:.4f}\")\n",
        "\n",
        "print(\"\\nTest Set Performance Comparison:\")\n",
        "print(\"  Default threshold (0.5):\")\n",
        "print(f\"    Accuracy:  {test_acc:.4f}\")\n",
        "print(f\"    Precision: {test_prec:.4f}\")\n",
        "print(f\"    Recall:    {test_rec:.4f}\")\n",
        "print(f\"    F1-Score:  {test_f1:.4f}\")\n",
        "\n",
        "print(f\"\\n  Optimized threshold ({best_threshold}):\")\n",
        "print(f\"    Accuracy:  {test_acc_opt:.4f} ({(test_acc_opt-test_acc)*100:+.2f}%)\")\n",
        "print(f\"    Precision: {test_prec_opt:.4f} ({(test_prec_opt-test_prec)*100:+.2f}%)\")\n",
        "print(f\"    Recall:    {test_rec_opt:.4f} ({(test_rec_opt-test_rec)*100:+.2f}%)\")\n",
        "print(f\"    F1-Score:  {test_f1_opt:.4f} ({(test_f1_opt-test_f1)*100:+.2f}%)\")\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "if test_rec_opt > test_rec:\n",
        "    print(\"  Recall improvement achieved, reducing false negative risk (clinically critical).\")\n",
        "if test_prec_opt < test_prec:\n",
        "    print(\"  Precision slightly decreased, increasing false positives.\")\n",
        "print(\"  Threshold selection reflects a controlled precisionrecall trade-off.\")"
      ],
      "metadata": {
        "id": "SUHvigdP5NwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "bqTRlmcGMYA_"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "NdXUgsAURas7",
        "mALlPGHPsulm",
        "pRI3v9sS9Qa5",
        "Ywd5rG4X7nVW",
        "38b7fMRKuJOq",
        "BHQ2SW2--JKP",
        "jnxMPbhHho8d"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}